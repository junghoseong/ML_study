{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLWYfc_W9K_I"
   },
   "source": [
    "# MobileNet V2 Tensorflow로 구현해보기 실습\n",
    "이번 실습에서는 Tensorflow Functional API를 이용하여 이미지를 구분하는 Neural Network를 MobileNet V2 구조로 구현해 보는 실습을 진행할 것이다. <br>\n",
    "그 중에서도 가장 핵심이라고 할 수 있는 Linear bottleneck과 Inverted residuals를 중점적으로 다룰 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3160,
     "status": "ok",
     "timestamp": 1613128595681,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "KG7udQjE9K_O"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import socket\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import struct\n",
    "from tqdm import tqdm\n",
    "from sys import getsizeof\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Add, ReLU, Input, Dense, Dropout, Activation, Flatten \\\n",
    "    , Conv2D, MaxPooling2D, InputLayer, Reshape, DepthwiseConv2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.engine.topology import Input\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3155,
     "status": "ok",
     "timestamp": 1613128595683,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "rbvEQunG9K_P"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend\n",
    "from tensorflow.python.keras.utils import layer_utils\n",
    "from tensorflow.python.keras.applications import imagenet_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4043,
     "status": "ok",
     "timestamp": 1613128596575,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "n6IUsj1_9K_Q"
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I02lfG3J9K_Q"
   },
   "source": [
    "## Setting GPU\n",
    "GPU가 없으면 아래 Step은 건너뛰어도 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycuHuKbR-szr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 719,
     "status": "ok",
     "timestamp": 1613129084393,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "qmdASH4V9K_Q",
    "outputId": "c02d707b-36d5-4382-d62d-279c9ecb8d98"
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "gpus\n",
    "idx = 0\n",
    "tf.config.experimental.set_visible_devices(gpus[idx], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[idx], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jn4C-28T9K_R"
   },
   "source": [
    "## Setting Hyperparameters\n",
    "훈련 데이터셋은 cifar10을 사용할 것이고, 주요 Hyperparameter들은 MobilenetV2의 ImageNet training에 사용한 값들을 사용할 것이다.<br>\n",
    "Classification을 위한 Hyperparameter들을 아래와 같이 설정한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "E34hkBk89K_R"
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "batch_size=96\n",
    "num_epochs   = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Syyyk87M9K_R"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "**앞의 Tutorial과 비슷한 방식으로 전처리하도록 수정 필요 TFDS를 활용...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsHhYd3i9K_S",
    "outputId": "1941e8f1-187c-4ead-f99e-63ca57ddf81d"
   },
   "source": [
    "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
    "!unzip tiny-imagenet-200.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7kdhvnQA9K_T",
    "outputId": "b0e019f3-c1f5-42a0-e2eb-65cf58710569"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "#(ds_train, ds_test), ds_info = tfds.load('cifar10', split=['train','test'], shuffle_files=True, as_supervised=True, with_info=True)\n",
    "\n",
    "train_images, val_images, train_labels, val_labels = model_selection.train_test_split(train_images, train_labels, test_size=0.5)\n",
    "train_images, val_images, test_images = train_images / 255.0, val_images / 255.0, test_images / 255.\n",
    "\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
    "val_labels = keras.utils.to_categorical(val_labels, num_classes)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYrFOOC49K_U"
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rF65gESu9K_U"
   },
   "outputs": [],
   "source": [
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor) # 더 가까운 divisor의 배수로 올림 4,5,6,7,8,9,10,11 -> 8, 12~19 -> 16 ...\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lcFLr56H9K_U"
   },
   "outputs": [],
   "source": [
    "#This is referenced from imagenet_utils source code\n",
    "#change in this part does not have influence on main code.\n",
    "def correct_pad(inputs, kernel_size):\n",
    "    \"\"\"Returns a tuple for zero-padding for 2D convolution with downsampling.\n",
    "    Arguments:\n",
    "    inputs: Input tensor.\n",
    "    kernel_size: An integer or tuple/list of 2 integers.\n",
    "    Returns:\n",
    "    A tuple.\n",
    "    \"\"\"\n",
    "    img_dim = 2 if backend.image_data_format() == 'channels_first' else 1\n",
    "    input_size = backend.int_shape(inputs)[img_dim:(img_dim + 2)]\n",
    "    if isinstance(kernel_size, int):\n",
    "        kernel_size = (kernel_size, kernel_size)\n",
    "    if input_size[0] is None:\n",
    "        adjust = (1, 1)\n",
    "    else:\n",
    "        adjust = (1 - input_size[0] % 2, 1 - input_size[1] % 2)\n",
    "    correct = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "    return ((correct[0] - adjust[0], correct[0]),\n",
    "          (correct[1] - adjust[1], correct[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDpfn0BU9K_U"
   },
   "source": [
    "### Inverted residual / Linear bottleneck layer\n",
    "3파트로 나누어 생각해 볼 수 있다.\n",
    "1. Expansion: 1x1 convolution으로 채널의 수를 expansion배만큼 증가시킨다. Activation은 RELU6이다.<br>\n",
    "2. Depthwise convolution: 3x3 convolution을 수행하며 Stride가 적용되어 Output의 size가Input과 달라질 수 있다. Activation은 RELU6이다.\n",
    "3. Linear bottleneck: 1x1 convolution으로 채널의 수를 filters로 줄여준다. <br>\n",
    "\n",
    "각 Layer에는 Batch normalization이 따라오고, 최종 위 3 단계를 거친 Layer와 Input을 합쳐서(Residual) return해주어야 한다.\n",
    "\n",
    "Hyper parameter의 경우는 ImageNet classification에 사용된 값을 준용하도록 하자.<br>\n",
    "BN에 사용되는 epsilon=0.001, momentum=0.999를 사용하자. <br>\n",
    "또한 Standard weight decay=0.00004를 사용하도록 하자.(L2 regularizer) <br>\n",
    "\n",
    "*TF mobilenetV2 소스코드상에는 없는데 standard weight decay가 L2 regularizer가 맞나? <br>\n",
    "make_divisible로 채널 크기가 8의 배수가 되도록 하는 이유는 무엇인가?<br>\n",
    "Depthwise Conv 2D에서 Zero padding을 추가적으로 해줘야 하는 이유가 있는지? padding=same으로 하면 안되는가?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DdOWKrVl9K_V"
   },
   "outputs": [],
   "source": [
    "def _inverted_res_block(inputs, expansion, stride, alpha, filters, block_id):\n",
    "    #Get the channel axis and the input channel size\n",
    "    channel_axis = 1 if backend.image_data_format() == 'channels_first' else -1\n",
    "    in_channels = backend.int_shape(inputs)[channel_axis]\n",
    "    \n",
    "    pointwise_conv_filters = int(alpha * filters)\n",
    "    pointwise_filters = _make_divisible(pointwise_conv_filters, 8) # Make sure the output filter size is the multiple of 8\n",
    "    \n",
    "    #Set the prefix\n",
    "    prefix = 'block_{}_'.format(block_id)\n",
    "    \n",
    "    x = inputs\n",
    "    \n",
    "    #Expansion block    \n",
    "    if block_id: # No expansion for block 0\n",
    "        x = layers.Conv2D(filters = expansion * in_channels, kernel_size = 1, strides = 1, padding='same',\n",
    "                          use_bias=False, activation=None, kernel_regularizer=regularizers.l2(0.00004),\n",
    "                          name=prefix + 'expand')(x)\n",
    "        x = layers.BatchNormalization(axis=channel_axis, momentum=0.999, epsilon=0.001, \n",
    "                                      name=prefix + 'expand_BN')(x)\n",
    "        x = layers.ReLU(6, name=prefix + 'expand_relu')(x)\n",
    "    else: \n",
    "        prefix = 'expanded_conv_'\n",
    "    \n",
    "    \n",
    "    #Depthwise convolution\n",
    "    #if stride == 2:\n",
    "        #Adjust zero paddings for strides, when input hieght and width are odd add (1,1,1,1) padding / when even, add (0,1,0,1)\n",
    "        #x = layers.ZeroPadding2D(padding=correct_pad(x, 3),\n",
    "        #                         name=prefix + 'pad')(x)\n",
    "    \n",
    "    x = layers.DepthwiseConv2D(kernel_size = 3, strides = stride, \n",
    "                               #padding='same' if stride == 1 else 'valid',\n",
    "                               padding='same',\n",
    "                               use_bias=False, activation=None, kernel_regularizer=regularizers.l2(0.00004),\n",
    "                               name=prefix + 'depthwise')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, momentum=0.999, epsilon=0.001,\n",
    "                                 name=prefix + 'depthwise_BN')(x)\n",
    "    x = layers.ReLU(6, name=prefix + 'relu')(x)\n",
    "    \n",
    "    #Pointwise convolution(Bottleneck)\n",
    "    x = layers.Conv2D(filters = pointwise_filters, kernel_size = 1, strides = 1, padding='same',\n",
    "                      use_bias=False, activation=None, kernel_regularizer=regularizers.l2(0.00004),\n",
    "                      name=prefix + 'project')(x)\n",
    "    x = layers.BatchNormalization(axis=channel_axis, momentum=0.999, epsilon=0.001,\n",
    "                                 name=prefix + 'project_BN')(x)\n",
    "    \n",
    "    #Inverted residual only when valid(Input size = output_size)\n",
    "    if in_channels == pointwise_filters and stride == 1:\n",
    "        return layers.add([inputs, x])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "iu8yF6Q-9K_V"
   },
   "outputs": [],
   "source": [
    "def MobileNetV2(input_shape,\n",
    "                classes,\n",
    "                alpha=1.0):\n",
    "    \n",
    "    \n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    first_block_filters = _make_divisible(32 * alpha, 8)\n",
    "    # first conv layer\n",
    "    x = layers.Conv2D(first_block_filters, kernel_size=3, strides=(2, 2), padding='same',  use_bias=False, \n",
    "                      bias_initializer='zeros',  kernel_regularizer=regularizers.l2(0.00004),\n",
    "                      name='Conv1')(inputs)\n",
    "    \n",
    "    x = layers.BatchNormalization(\n",
    "      axis=-1, epsilon=1e-3, momentum=0.999, name='bn_Conv1')(x)\n",
    "    \n",
    "    x = layers.ReLU(6., name='Conv1_relu')(x)\n",
    "    \n",
    "    \n",
    "    # inverted residual blocks\n",
    "    x = _inverted_res_block(\n",
    "      x, filters=16, alpha=alpha, stride=1, expansion=1, block_id=0)\n",
    "\n",
    "    x = _inverted_res_block(\n",
    "      x, filters=24, alpha=alpha, stride=2, expansion=6, block_id=1)\n",
    "    x = _inverted_res_block(\n",
    "      x, filters=24, alpha=alpha, stride=1, expansion=6, block_id=2)\n",
    "\n",
    "    x = _inverted_res_block(\n",
    "      x, filters=32, alpha=alpha, stride=2, expansion=6, block_id=3)\n",
    "    x = _inverted_res_block(\n",
    "      x, filters=32, alpha=alpha, stride=1, expansion=6, block_id=4)\n",
    "    x = _inverted_res_block(\n",
    "      x, filters=32, alpha=alpha, stride=1, expansion=6, block_id=5)\n",
    "\n",
    "    x = _inverted_res_block(\n",
    "      x, filters=64, alpha=alpha, stride=2, expansion=6, block_id=6)\n",
    "    x = _inverted_res_block(\n",
    "      x, filters=64, alpha=alpha, stride=1, expansion=6, block_id=7)\n",
    "    x = _inverted_res_block(\n",
    "      x, filters=64, alpha=alpha, stride=1, expansion=6, block_id=8)\n",
    "    x = _inverted_res_block(\n",
    "      x, filters=64, alpha=alpha, stride=1, expansion=6, block_id=9)\n",
    "\n",
    "    x = _inverted_res_block(\n",
    "      x, filters=96, alpha=alpha, stride=1, expansion=6, block_id=10)\n",
    "    x = _inverted_res_block(\n",
    "      x, filters=96, alpha=alpha, stride=1, expansion=6, block_id=11)\n",
    "    x = _inverted_res_block(\n",
    "      x, filters=96, alpha=alpha, stride=1, expansion=6, block_id=12)\n",
    "\n",
    "    x = _inverted_res_block(\n",
    "      x, filters=160, alpha=alpha, stride=2, expansion=6, block_id=13)\n",
    "    x = _inverted_res_block(\n",
    "      x, filters=160, alpha=alpha, stride=1, expansion=6, block_id=14)\n",
    "    x = _inverted_res_block(\n",
    "      x, filters=160, alpha=alpha, stride=1, expansion=6, block_id=15)\n",
    "\n",
    "    x = _inverted_res_block(\n",
    "      x, filters=320, alpha=alpha, stride=1, expansion=6, block_id=16)\n",
    "    \n",
    "    \n",
    "    if alpha > 1.0:\n",
    "        last_block_filters = _make_divisible(1280 * alpha, 8)\n",
    "    else:\n",
    "        last_block_filters = 1280    \n",
    "    \n",
    "    # conv layer\n",
    "    x = layers.Conv2D(last_block_filters, \n",
    "                      kernel_size=1, \n",
    "                      use_bias=False,                                              \n",
    "                      kernel_regularizer=regularizers.l2(0.00004),                      \n",
    "                      name='Conv_1')(x)\n",
    "    \n",
    "    x = layers.BatchNormalization(axis=-1, \n",
    "                                  epsilon=1e-3, \n",
    "                                  momentum=0.999, \n",
    "                                  name='Conv_1_bn')(x)\n",
    "    \n",
    "    x = layers.ReLU(6., name='out_relu')(x)\n",
    "    \n",
    "    # average pooling\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # FC layer\n",
    "    outputs = layers.Dense(classes, \n",
    "                           activation='softmax',                                                        \n",
    "                           kernel_regularizer=regularizers.l2(0.00004),                           \n",
    "                           name='predictions')(x)\n",
    "\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1776,
     "status": "ok",
     "timestamp": 1613128610998,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "qfIDRDut9K_W"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 300\n",
    "n_classes = 10\n",
    "max_output_size = 200\n",
    "pos_iou_threshold = 0.5\n",
    "neg_iou_threshold = 0.5\n",
    "score_threshold = 0.01\n",
    "layer_width=[38,19,10,5,3,1]\n",
    "num_boxes = [4,6,6,6,4,4]\n",
    "aspect_ratio = [1,1,2,1/2,3,1/3]\n",
    "s_max = 0.9\n",
    "s_min = 0.2\n",
    "batch_size = 32\n",
    "log_dir = './'\n",
    "model_name = 'mobilenetSSD'\n",
    "model_csv_path  = os.path.join(log_dir, (model_name + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6160,
     "status": "ok",
     "timestamp": 1613128615921,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "Lx-y9VE29K_X",
    "outputId": "589ccf7b-896d-42f3-8e15-449aba9b5095"
   },
   "outputs": [],
   "source": [
    "#Load data\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 13719,
     "status": "ok",
     "timestamp": 1613128624080,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "64Q9DYNh9K_X",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "train_size = x_train.shape[0]\n",
    "x_train_resize = np.zeros((train_size, 64, 64, 3))\n",
    "test_size = x_test.shape[0]\n",
    "x_test_resize = np.zeros((test_size, 64, 64, 3))\n",
    "\n",
    "for i, image in enumerate(x_train):\n",
    "    x_train_resize[i] = cv2.resize(image, dsize=(64, 64), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "for i, image in enumerate(x_test):\n",
    "    x_test_resize[i] = cv2.resize(image, dsize=(64, 64), interpolation=cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "gVvKAQpN9K_X"
   },
   "outputs": [],
   "source": [
    "def convert(x, y, small_x, canvas_size):\n",
    "    \"\"\"\n",
    "    Convert classification data to object detection data\n",
    "    Randomly locate image in the middle of black canvas    \n",
    "    Input\n",
    "        x: Image, shape: (batch_size, image size, image size, #channels)\n",
    "        y: label, shape: (batch_size, )\n",
    "    output\n",
    "        out_x: Image located in the random location of black canvas, shape: (batch_size, canvas size, canvas size, 3)\n",
    "        out_y: label and location of corners(xmin,ymin,xmax,ymax), shape: (batch_size, #objects per image, 1+4) #Objects per image = 1\n",
    "                                                                \n",
    "    \"\"\"\n",
    "    #get batch size and image size\n",
    "    batch_size = 32\n",
    "    image_size = x.shape[-2]\n",
    "    small_image_size = small_x.shape[-2]\n",
    "    channels = x.shape[-1]\n",
    "    \n",
    "    #prepare black canvas\n",
    "    canvas = np.zeros((batch_size, canvas_size, canvas_size, channels), dtype=np.int)\n",
    "    out_y = np.zeros((batch_size,2, 5))\n",
    "    \n",
    "    xmin = np.random.randint(canvas_size - image_size, size = (batch_size,))\n",
    "    ymin = np.random.randint(canvas_size - image_size, size = (batch_size,))\n",
    "    xmax = xmin + image_size\n",
    "    ymax = ymin + image_size\n",
    "    \n",
    "    small_xmin = np.zeros(batch_size, dtype=np.int)\n",
    "    small_ymin = np.zeros(batch_size, dtype=np.int)\n",
    "    small_xmax = np.zeros(batch_size, dtype=np.int)\n",
    "    small_ymax = np.zeros(batch_size, dtype=np.int)\n",
    "        \n",
    "    for i in range(batch_size):\n",
    "        canvas[i, xmin[i]:xmax[i], ymin[i]:ymax[i], :] = x[i]\n",
    "        if canvas_size - xmax[i]> xmin[i]:\n",
    "            small_xmin[i] = np.random.randint(xmax[i], canvas_size - small_image_size)\n",
    "        else: \n",
    "            small_xmin[i] = np.random.randint(xmin[i])\n",
    "            \n",
    "        if canvas_size - ymax[i] > ymin[i]:\n",
    "            small_ymin[i] = np.random.randint(ymax[i], canvas_size - small_image_size)\n",
    "        else: \n",
    "            small_ymin[i] = np.random.randint(ymin[i])\n",
    "            \n",
    "        small_xmax[i] = small_xmin[i] + small_image_size\n",
    "        small_ymax[i] = small_ymin[i] + small_image_size\n",
    "        \n",
    "        canvas[i, small_xmin[i]:small_xmax[i], small_ymin[i]:small_ymax[i], :] = small_x[i]\n",
    "        \n",
    "        \n",
    "    out_y[:,0,0] = y[:,0]\n",
    "    out_y[:,1,0] = y[:,0]\n",
    "    out_y[:, 0, -4:] = np.column_stack([xmin, ymin, xmax, ymax])\n",
    "    out_y[:, 1, -4:] = np.column_stack([small_xmin, small_ymin, small_xmax, small_ymax])    \n",
    "    \n",
    "    return canvas, out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 6890,
     "status": "ok",
     "timestamp": 1613128624593,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "AEE8gy_h9K_Y"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353,
     "referenced_widgets": [
      "b431f65b3b254cc6a3e5c8b52b8cd94b",
      "f0f704e333824d88a1e500181657c811",
      "2ab7e70e71cb43839059e0c98a5588ce",
      "32fb297f13f14d7aaf620bee707b0c93",
      "385dc23d1c6f4a78a8a169b47ae85802",
      "55c71cce9c134fe4aef64c8fad66517f",
      "3f7d53d5923749dd943f3c861ce51117",
      "8dda30ea6cdd49d59e78976b9cf42009",
      "a2ff4fc99413416e90a395e2d97a99e7",
      "2608bdced506428096e088db539c7ad9",
      "55493dd5e4fd465098bc70ff37e69db0",
      "419af6b5b997403c95a1e65312a3e860",
      "407265d3cf8049e0991a972d0d479ece",
      "4ff7afb64cbd4186b40f92065dfb82ac",
      "a77b136604ec4a2cba8fe68a0d2dbf9b",
      "0859bab71eab47fbb590007039f39a3e",
      "b8e2b8e04343446ab154218db45511b8",
      "fb775dedd2ed4a788147186b938a1cb6",
      "571c240f947a4d15ae78455c4a72f9b4",
      "0e905de5c373451b893300c1762b57fd",
      "76bae7cb1859498f8409bcd9e30a9c34",
      "f639f557bd10413984105589e2f4b591",
      "31eccb666655419081e2ac8d5ebcb565",
      "8773c576980a46f88c96bed1b2c3ed4c",
      "80e50241164841aeba862927d2feee97",
      "28b40640b9fe459fb831f226cb47db77",
      "889032f1a36745f68ec2bdb4a02e027e",
      "32709ba74bb94ca1ad8d34054055cabe",
      "97dd481a5a4c4cc39e0938425f6a1fb3",
      "dd6b681892134c84b5ff7af3e7bfcf8e",
      "9bb929653cc44291b30b7fe1fd434112",
      "08c9f1d4d5b54c89ba25408245698d65",
      "29040801c9c648098c6325fd9d378335",
      "550e1b3b7b2e4fcf86af1f85a6fbc25b",
      "cc56730809984a7ba5b56d23e47f2801",
      "12412c91f4174c7f862a69d35f7c13f0",
      "bf435f29ce0d4453b06d1d47a26efcdc",
      "cbd353891b784c9385e538ba6393b264",
      "e22ac0c707a14a759dad90dfbb129e56",
      "d6e57c0dbe654a38a3699eb60cf05fcb",
      "7f8e45ed7b0e44d9b8a00649f8adac3e",
      "5493d675213f4e17a683ff9d6f97fc53",
      "ddb41ebea79c4253b360d4daf7589ff7",
      "aa059c294a97454e82a88da4ed3e5bdc",
      "472ef399bf364248ae5ade0826aaaeac",
      "89085c51c0654b5d8c39dba0e68bd8cb",
      "cb1ab90424ee4bbf980e16539a3b4415",
      "3bd6270ce53849a1895099e7f8b17ccb",
      "37b62a85ad3541f186b525270faf83e4",
      "b43c4bbc415e444098b947a1461abd84",
      "be9a07eb56ac4c59894ed173d57293d2",
      "dc3679c7120b43858f4f1787cb6e28cd",
      "eb48fcf80e8749b38168a99e1ed35747",
      "cbfee4abb7cd42a9b10f15891edc0d4c",
      "64591e2e98f04e08968607743f928be5",
      "b7b66bc0f6e84e07a6f96c976625b7fe"
     ]
    },
    "executionInfo": {
     "elapsed": 57944,
     "status": "ok",
     "timestamp": 1613128675939,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "dx5qT19M9K_Y",
    "outputId": "2e349af7-9076-4dde-942b-357c32e819c9"
   },
   "outputs": [],
   "source": [
    "(dataset_train, dataset_test), ds_info = tfds.load(\n",
    "    'cifar10',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 57316,
     "status": "ok",
     "timestamp": 1613128675941,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "H6Ab4iiB9K_Y"
   },
   "outputs": [],
   "source": [
    "def convert_image_ds(image, label):\n",
    "    \"\"\"\n",
    "    Convert classification data to object detection data\n",
    "    Randomly locate image in the middle of black canvas    \n",
    "    Input\n",
    "        x: Image, shape: (batch_size, image size, image size, #channels)\n",
    "        y: label, shape: (batch_size, )\n",
    "    output\n",
    "        out_x: Image located in the random location of black canvas, shape: (batch_size, canvas size, canvas size, 3)\n",
    "        out_y: label and location of corners(xmin,ymin,xmax,ymax), shape: (batch_size, #objects per image, 1+4) #Objects per image = 1\n",
    "                                                                \n",
    "    \"\"\"\n",
    "    #get batch size and image size\n",
    "    image_size = image.shape[-2]\n",
    "    channels = image.shape[-1]\n",
    "    \n",
    "    #prepare black canvas\n",
    "    canvas = np.zeros((300, 300, channels), dtype=np.int)\n",
    "    out_y = np.zeros((1,5))\n",
    "    \n",
    "    xmin = np.random.randint(300 - image_size)\n",
    "    ymin = np.random.randint(300 - image_size)\n",
    "    xmax = xmin + image_size\n",
    "    ymax = ymin + image_size\n",
    "           \n",
    "    canvas[xmin:xmax, ymin:ymax, :] = image\n",
    "        \n",
    "        \n",
    "    out_y[0,0] = label\n",
    "    out_y[0,-4:] = [xmin, ymin, xmax, ymax]   \n",
    "    \n",
    "    return canvas, out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 56173,
     "status": "ok",
     "timestamp": 1613128675942,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "OY50MOL49K_Y"
   },
   "outputs": [],
   "source": [
    "def convert_ds_wrap(image, label):\n",
    "    canvas_shape = [300,300,3]\n",
    "    label_shape = [1,5]\n",
    "    [image_mod, label_mod] = tf.py_function(convert_image_ds, [image, label], [tf.int32, tf.int32])\n",
    "    \n",
    "    image_mod.set_shape(canvas_shape)\n",
    "    label_mod.set_shape(label_shape)\n",
    "    \n",
    "    return image_mod, label_mod    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 55882,
     "status": "ok",
     "timestamp": 1613128676212,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "WMxImzWN9K_Y"
   },
   "outputs": [],
   "source": [
    "ds_train = dataset_train.map(\n",
    "    convert_ds_wrap, \n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "    deterministic=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 55144,
     "status": "ok",
     "timestamp": 1613128676213,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "3CslVoU_9K_Z"
   },
   "outputs": [],
   "source": [
    "def show(image, label):\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.title(label.numpy())\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "executionInfo": {
     "elapsed": 54566,
     "status": "ok",
     "timestamp": 1613128676547,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "mUD12WuI9K_Z",
    "outputId": "3a618c2f-e019-4c25-ae02-ab4261ec32b1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image, label in ds_train.take(1):\n",
    "    show(image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "executionInfo": {
     "elapsed": 876,
     "status": "error",
     "timestamp": 1613128680400,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "KahAlN739K_Z",
    "outputId": "6608d154-bb1c-4a9e-c44c-beaf142726e1"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (50000) into shape (32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-77e4297b9698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train_od\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_od\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_resize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_test_od\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_od\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_resize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-50d7240b4a42>\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(x, y, small_x, canvas_size)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mout_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mout_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mout_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymax\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (50000) into shape (32)"
     ]
    }
   ],
   "source": [
    "x_train_od, y_train_od = convert(x_train_resize, y_train, x_train, IMG_SIZE)\n",
    "x_test_od, y_test_od = convert(x_test_resize, y_test, x_test, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 667,
     "status": "ok",
     "timestamp": 1613128683457,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "DxLxHJgA9K_Z"
   },
   "outputs": [],
   "source": [
    "def calc_iou(gt, anchor_boxes):        \n",
    "        \"\"\"\n",
    "        Calculate IOU of ground truth and anchor boxes\n",
    "        \n",
    "        Input:\n",
    "            gt: ground truth image, shape: (#object per image, 4)\n",
    "            anchor_boxes: anchor boxes, shape: (sum of grid size of all classifier * num_boxes, 4)\n",
    "        Output:\n",
    "            Matrix of iou. Row indicates each ground truth box and column indicates each anchor box.\n",
    "            shape: (#object per image, sum of grid size of all classifier)\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        i_xmin = 0\n",
    "        i_ymin = 1\n",
    "        i_xmax = 2\n",
    "        i_ymax = 3        \n",
    "        \n",
    "        m = gt.shape[0] # Object per image\n",
    "        n = anchor_boxes.shape[0] # Number of all boxes\n",
    "        \n",
    "        #Calculate min_xy\n",
    "        min_xy = np.maximum(np.tile(np.expand_dims(gt[:,0:2], axis = 1), reps = (1,n,1)),\n",
    "                            np.tile(np.expand_dims(anchor_boxes[:, 0:2], axis = 0), reps = (m,1,1)))\n",
    "        \n",
    "        #Calculate max_xy\n",
    "        max_xy = np.minimum(np.tile(np.expand_dims(gt[:,2:4], axis = 1), reps = (1,n,1)),\n",
    "                            np.tile(np.expand_dims(anchor_boxes[:, 2:4], axis = 0), reps = (m,1,1)))\n",
    "        \n",
    "        #calculate intersection\n",
    "        intersection = np.maximum((max_xy - min_xy)[:,:,0],0) * np.maximum((max_xy - min_xy)[:,:,1],0)\n",
    "        \n",
    "        #calculate union\n",
    "        edge_gt = np.tile(np.expand_dims(gt[:,2:4] - gt[:,0:2], axis = 1), reps = (1,n,1))         \n",
    "        area_gt = edge_gt[:,:,0] * edge_gt[:,:,1]\n",
    "        \n",
    "        edge_anchor_boxes = np.tile(np.expand_dims(anchor_boxes[:,2:4] - anchor_boxes[:,0:2], axis = 0), reps = (m,1,1))         \n",
    "        area_anchor_boxes = edge_anchor_boxes[:,:,0] * edge_anchor_boxes[:,:,1]\n",
    "\n",
    "        union = area_gt + area_anchor_boxes - intersection\n",
    "        \n",
    "        return intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1613128683799,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "sAn75-vQ9K_Z"
   },
   "outputs": [],
   "source": [
    "def match_bipartite_greedy(weight_matrix):\n",
    "    \"\"\"\n",
    "    Calculate the highest matching anchor box per each ground truth\n",
    "    Input: iou between each ground truth and anchor boxes, shape: (#gt, #anchor boxes)\n",
    "    Output: List of matched anchor per each ground truth\n",
    "    \"\"\"\n",
    "    m = weight_matrix.shape[0]\n",
    "    n = weight_matrix.shape[1]\n",
    "    \n",
    "    matches = np.zeros(m, dtype = np.int)\n",
    "    weight_cp = np.copy(weight_matrix)\n",
    "    \n",
    "    #Find the largest iou per each ground truth box in descending order\n",
    "    for _ in range(m):\n",
    "        largest_indices = np.argmax(weight_cp, axis = 1)\n",
    "        iou_largest = weight_cp[list(range(m)), largest_indices]\n",
    "        match_gt = np.argmax(iou_largest, axis = 0)\n",
    "        match_anchor = largest_indices[match_gt]\n",
    "        matches[match_gt] = match_anchor\n",
    "        \n",
    "        #Set the selected ground truth to 0, matched anchor box to 0 as well.\n",
    "        weight_cp[match_gt, :] = 0\n",
    "        weight_cp[:, match_anchor] = 0\n",
    "        \n",
    "    return matches    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 563,
     "status": "ok",
     "timestamp": 1613128684296,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "oEKuBa-W9K_a"
   },
   "outputs": [],
   "source": [
    "def match_multi(weight_matrix, threshold):\n",
    "    \"\"\"\n",
    "    Multiple object match\n",
    "    From remaining anchor boxexk, find the most similar ground truth \n",
    "    whose iou is greater than pos_threshold\n",
    "    \"\"\"\n",
    "    m = weight_matrix.shape[0]\n",
    "    n = weight_matrix.shape[1]\n",
    "\n",
    "    #Find the largest iou per each anchor box\n",
    "    largest_indices = np.argmax(weight_matrix, axis = 0)\n",
    "    iou_largest = weight_matrix[largest_indices, list(range(n))]\n",
    "    \n",
    "    #Filter iou is greater than the threshold\n",
    "    matches_anchor = np.nonzero(iou_largest >= threshold)[0].astype(np.int)\n",
    "    matches_gt = iou_largest[matches_anchor].astype(np.int)\n",
    "    \n",
    "    return matches_anchor, matches_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 597,
     "status": "ok",
     "timestamp": 1613128684951,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "lEgKOTIt9K_a"
   },
   "outputs": [],
   "source": [
    "def convert_coord(boxes, type='centroid2corner'):\n",
    "    \"\"\"\n",
    "        Input: Input labels \n",
    "        type: how to convert\n",
    "            centroid2corner: (cx, cy, w, h) -> (xmin, ymin, xmax, ymax)\n",
    "            corner2centroid: (xmin, ymin, xmax, ymax) -> (cx, cy, w, h)    \n",
    "    \"\"\"\n",
    "    \n",
    "    if type=='centroid2corner':\n",
    "        cx = boxes[..., 0]\n",
    "        cy = boxes[..., 1]\n",
    "        w = boxes[..., 2]\n",
    "        h = boxes[..., 3]\n",
    "        \n",
    "        converted_boxes = np.copy(boxes)\n",
    "        converted_boxes[..., 0] = cx - w / 2 #xmin\n",
    "        converted_boxes[..., 1] = cy - h / 2 #ymin\n",
    "        converted_boxes[..., 2] = cx + w / 2 #xmax\n",
    "        converted_boxes[..., 3] = cy + h / 2 #ymax\n",
    "    elif type=='corner2centroid':\n",
    "        xmin = boxes[..., 0]\n",
    "        ymin = boxes[..., 1]\n",
    "        xmax = boxes[..., 2]\n",
    "        ymax = boxes[..., 3]\n",
    "        \n",
    "        converted_boxes = np.copy(boxes)\n",
    "        \n",
    "        converted_boxes[..., 0] = (xmin + xmax) / 2 #cx\n",
    "        converted_boxes[..., 1] = (ymin + ymax) / 2 #cy\n",
    "        converted_boxes[..., 2] = xmax - xmin #w\n",
    "        converted_boxes[..., 3] = ymax - ymin #h\n",
    "        \n",
    "    return converted_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 788,
     "status": "ok",
     "timestamp": 1613128685847,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "LgIBKPxo9K_a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SSDInputEncoder():\n",
    "    def __init__(self, \n",
    "                 img_height, \n",
    "                 img_width, \n",
    "                 layer_width, \n",
    "                 n_classes, \n",
    "                 num_boxes, \n",
    "                 s_max, \n",
    "                 s_min, \n",
    "                 aspect_ratio, \n",
    "                 pos_iou_threshold,\n",
    "                 neg_iou_threshold,\n",
    "                background_id):\n",
    "        #Consider Background class\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.n_classes = n_classes + 1  #Add background class\n",
    "        self.num_boxes = num_boxes  #List of number of boxes in each classifier layer\n",
    "        self.s_max = s_max # Largest scale of default box\n",
    "        self.s_min = s_min # Smallest scale of default box\n",
    "        self.aspect_ratio = aspect_ratio # List of aspect ratios\n",
    "        self.layer_width = layer_width\n",
    "        self.pos_iou_threshold = pos_iou_threshold\n",
    "        self.neg_iou_threshold = neg_iou_threshold\n",
    "        self.background_id = background_id\n",
    "        \n",
    "        \n",
    "    def __call__(self, gt_label):\n",
    "        \"\"\"\n",
    "        Input: ground truth label,shape: (batch_size, #object per image, 1 + 4)\n",
    "        Output: y_encoded, shape: (batch_size, sum of grid size of all classifier * num_boxes, n_classes + 4 + 4)\n",
    "        1. Create y_encoded template: (B, num_boxes, class + 4 + 4) 4 for gt coordinates and 4 for anchor boxes\n",
    "        2. For each ground truth, calculate iou of gt and anchor boxes\n",
    "        3. Find the highest matching anchor box per each gt and fill in y_encoded template\n",
    "        4. Multi object matching\n",
    "        5. Apply negative iou threshold\n",
    "        6. Transform into Delta format\n",
    "        \"\"\"\n",
    "        batch_size = gt_label.shape[0]        \n",
    "        sum_l2 = 0\n",
    "        \n",
    "        i_xmin = 0\n",
    "        i_ymin = 1\n",
    "        i_xmax = 2\n",
    "        i_ymax = 3\n",
    "        \n",
    "        # Make class vector to one hot format\n",
    "        class_vector = np.eye(self.n_classes)\n",
    "        \n",
    "        \n",
    "        for iw in range(len(layer_width)):\n",
    "            s = s_min + (s_max - s_min) / (len(layer_width) - 1) * (len(layer_width) - iw - 1)\n",
    "            l = layer_width[iw]            \n",
    "            num_box = self.num_boxes[iw]            \n",
    "            box_tensor = np.zeros((l * l * num_box, 4))\n",
    "            for i in range(layer_width[iw]):                    \n",
    "                for j in range(layer_width[iw]):\n",
    "                    for box_idx in range(num_box):\n",
    "                        box_tensor[(i * l + j) * num_box + box_idx, 0]  = (0.5 + i) / l * self.img_width\n",
    "                        box_tensor[(i * l + j) * num_box + box_idx, 1]  = (0.5 + j) / l * self.img_height\n",
    "                        \n",
    "                        if box_idx == 0:\n",
    "                            s_next = s_min + (s_max - s_min) / (len(layer_width) - 1) * (len(layer_width) - iw)\n",
    "                            box_tensor[(i * l + j) * num_box + box_idx, 2]  = math.sqrt(aspect_ratio[box_idx]) / l * math.sqrt(s * s_next) * self.img_width\n",
    "                            box_tensor[(i * l + j) * num_box + box_idx, 3]  = 1 / math.sqrt(aspect_ratio[box_idx]) / l * math.sqrt(s * s_next) * self.img_height                            \n",
    "                        else:                            \n",
    "                            box_tensor[(i * l + j) * num_box + box_idx, 2]  = math.sqrt(aspect_ratio[box_idx]) / l * s * self.img_width\n",
    "                            box_tensor[(i * l + j) * num_box + box_idx, 3]  = 1 / math.sqrt(aspect_ratio[box_idx]) / l * s * self.img_height\n",
    "                        \n",
    "            box_tensor = convert_coord(box_tensor, type='centroid2corner')\n",
    "            \n",
    "            if iw == 0:\n",
    "                boxes_tensor = box_tensor                \n",
    "            else:                    \n",
    "                boxes_tensor = np.concatenate((boxes_tensor, box_tensor), axis = 0)\n",
    "            \n",
    "            class_tensor = np.zeros((l * l * num_box , self.n_classes))\n",
    "            \n",
    "            if iw == 0:\n",
    "                classes_tensor = class_tensor                \n",
    "            else:                    \n",
    "                classes_tensor = np.concatenate((classes_tensor, class_tensor), axis = 0)\n",
    "                \n",
    "        box_class_tensor= np.concatenate((classes_tensor, boxes_tensor, boxes_tensor), axis = 1)\n",
    "        y_encoded = np.tile(box_class_tensor, (batch_size, 1, 1))\n",
    "        \n",
    "        y_encoded[:, :, self.background_id] = 1 # All boxes are background boxes by default.\n",
    "        \n",
    "    \n",
    "        for i in range(batch_size):\n",
    "            gt_one_label = gt_label[i]\n",
    "            m = gt_one_label.shape[0]\n",
    "            if gt_one_label.shape[0] == 0: continue # If there is no object, skip\n",
    "            \n",
    "            #FInd the iou of ground truth and all anchor boxes\n",
    "            similarities = calc_iou(gt_one_label[:,-4:], y_encoded[i, :, -4:])            \n",
    "            \n",
    "            #Find the highest matching anchor box per each ground truth boxes\n",
    "            matches = match_bipartite_greedy(similarities)\n",
    "            \n",
    "            #Convert ground truth class label to one hot encoding            \n",
    "            gt_class = np.array(gt_one_label[:,0], dtype=np.int)\n",
    "                        \n",
    "            #Fill in y_encoded\n",
    "            y_encoded[i, matches, :self.n_classes] = class_vector[gt_class]\n",
    "            y_encoded[i, matches, -8:-4] = gt_one_label[:,1:]\n",
    "            \n",
    "            #Set the matched anchor boxes to 0 to indicate they are matched before multi object matching\n",
    "            similarities[:,matches] = 0\n",
    "            \n",
    "            \n",
    "            #Multi object matching\n",
    "            #Similar process to bipartite matching\n",
    "            matches_anchor, matches_gt = match_multi(similarities, threshold=self.pos_iou_threshold)            \n",
    "            \n",
    "            if len(matches_gt) > 0:            \n",
    "\n",
    "                y_encoded[i, matches_anchor, :self.n_classes] = class_vector[gt_class[matches_gt]]           \n",
    "                y_encoded[i, matches_anchor, -8:-4] = gt_one_label[matches_gt,1:]\n",
    "\n",
    "                #Set the matched anchor boxes to 0 to indicate they are matched before applying negative iou threshold\n",
    "                similarities[:,matches_anchor] = 0\n",
    "            \n",
    "            #All background boxes whose iou are greater than neg_iou_threshold \n",
    "            # are set to neutral(neither background nor class)\n",
    "            max_bg_similarities = np.amax(similarities, axis = 0)\n",
    "            neutral_boxes = np.nonzero(max_bg_similarities >= self.neg_iou_threshold)[0]\n",
    "            y_encoded[i, neutral_boxes, self.background_id] = 0\n",
    "        \n",
    "        y_encoded[:,:,[-8, -7]] -= y_encoded[:,:,[-4, -3]] # (cx(gt) - cx(d_box)) # (cy(gt) - cy(d_box))\n",
    "        y_encoded[:,:,[-8, -7]] /= y_encoded[:,:,[-2, -1]] # (cx(gt) - cx(d_box)) / w(d_box) # (cy(gt) - cy(d_box)) / h(d_box)\n",
    "        y_encoded[:,:,[-6, -5]] = np.log(y_encoded[:,:,[-6, -5]] / y_encoded[:,:,[-2, -1]]) #log(w(gt) / w(d_box)) #log(h(gt) / h(d_box))\n",
    "                  \n",
    "        return y_encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "executionInfo": {
     "elapsed": 413,
     "status": "error",
     "timestamp": 1613128686187,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "VlI4xbYK9K_a",
    "outputId": "857ceec1-645b-403c-8eb6-95bcf2cb818e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train_od' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-fcaaf4cdf305>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                  \u001b[0mneg_iou_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneg_iou_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                  background_id=10)\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0my_train_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mssd_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_od\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0my_test_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mssd_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_od\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train_od' is not defined"
     ]
    }
   ],
   "source": [
    "ssd_input = SSDInputEncoder(IMG_SIZE, \n",
    "                 IMG_SIZE, \n",
    "                 layer_width=layer_width, \n",
    "                 n_classes=n_classes, \n",
    "                 num_boxes=num_boxes, \n",
    "                 s_max=s_max, \n",
    "                 s_min=s_min, \n",
    "                 aspect_ratio=aspect_ratio, \n",
    "                 pos_iou_threshold=pos_iou_threshold,\n",
    "                 neg_iou_threshold=neg_iou_threshold,\n",
    "                 background_id=10)\n",
    "y_train_encoded = ssd_input(y_train_od)\n",
    "y_test_encoded = ssd_input(y_test_od)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 710,
     "status": "ok",
     "timestamp": 1613128692183,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "oTJ-Ywcu9K_b"
   },
   "outputs": [],
   "source": [
    "class SSDInputEncoder_ds():\n",
    "    def __init__(self, \n",
    "                 img_height, \n",
    "                 img_width, \n",
    "                 layer_width, \n",
    "                 n_classes, \n",
    "                 num_boxes, \n",
    "                 s_max, \n",
    "                 s_min, \n",
    "                 aspect_ratio, \n",
    "                 pos_iou_threshold,\n",
    "                 neg_iou_threshold,\n",
    "                background_id):\n",
    "        #Consider Background class\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.n_classes = n_classes + 1  #Add background class\n",
    "        self.num_boxes = num_boxes  #List of number of boxes in each classifier layer\n",
    "        self.s_max = s_max # Largest scale of default box\n",
    "        self.s_min = s_min # Smallest scale of default box\n",
    "        self.aspect_ratio = aspect_ratio # List of aspect ratios\n",
    "        self.layer_width = layer_width\n",
    "        self.pos_iou_threshold = pos_iou_threshold\n",
    "        self.neg_iou_threshold = neg_iou_threshold\n",
    "        self.background_id = background_id\n",
    "        \n",
    "        \n",
    "    def __call__(self, gt_label):\n",
    "        \"\"\"\n",
    "        Input: ground truth label,shape: (batch_size, #object per image, 1 + 4)\n",
    "        Output: y_encoded, shape: (batch_size, sum of grid size of all classifier * num_boxes, n_classes + 4 + 4)\n",
    "        1. Create y_encoded template: (B, num_boxes, class + 4 + 4) 4 for gt coordinates and 4 for anchor boxes\n",
    "        2. For each ground truth, calculate iou of gt and anchor boxes\n",
    "        3. Find the highest matching anchor box per each gt and fill in y_encoded template\n",
    "        4. Multi object matching\n",
    "        5. Apply negative iou threshold\n",
    "        6. Transform into Delta format\n",
    "        \"\"\"\n",
    "                \n",
    "        i_xmin = 0\n",
    "        i_ymin = 1\n",
    "        i_xmax = 2\n",
    "        i_ymax = 3\n",
    "        \n",
    "        # Make class vector to one hot format\n",
    "        class_vector = np.eye(self.n_classes)        \n",
    "        \n",
    "        for iw in range(len(layer_width)):\n",
    "            s = s_min + (s_max - s_min) / (len(layer_width) - 1) * (len(layer_width) - iw - 1)\n",
    "            l = layer_width[iw]            \n",
    "            num_box = self.num_boxes[iw]            \n",
    "            box_tensor = np.zeros((l * l * num_box, 4))\n",
    "            for i in range(layer_width[iw]):                    \n",
    "                for j in range(layer_width[iw]):\n",
    "                    for box_idx in range(num_box):\n",
    "                        box_tensor[(i * l + j) * num_box + box_idx, 0]  = (0.5 + i) / l * self.img_width\n",
    "                        box_tensor[(i * l + j) * num_box + box_idx, 1]  = (0.5 + j) / l * self.img_height\n",
    "                        \n",
    "                        if box_idx == 0:\n",
    "                            s_next = s_min + (s_max - s_min) / (len(layer_width) - 1) * (len(layer_width) - iw)\n",
    "                            box_tensor[(i * l + j) * num_box + box_idx, 2]  = math.sqrt(aspect_ratio[box_idx]) / l * math.sqrt(s * s_next) * self.img_width\n",
    "                            box_tensor[(i * l + j) * num_box + box_idx, 3]  = 1 / math.sqrt(aspect_ratio[box_idx]) / l * math.sqrt(s * s_next) * self.img_height                            \n",
    "                        else:                            \n",
    "                            box_tensor[(i * l + j) * num_box + box_idx, 2]  = math.sqrt(aspect_ratio[box_idx]) / l * s * self.img_width\n",
    "                            box_tensor[(i * l + j) * num_box + box_idx, 3]  = 1 / math.sqrt(aspect_ratio[box_idx]) / l * s * self.img_height\n",
    "                        \n",
    "            box_tensor = convert_coord(box_tensor, type='centroid2corner')\n",
    "            \n",
    "            if iw == 0:\n",
    "                boxes_tensor = box_tensor                \n",
    "            else:                    \n",
    "                boxes_tensor = np.concatenate((boxes_tensor, box_tensor), axis = 0)\n",
    "            \n",
    "            class_tensor = np.zeros((l * l * num_box , self.n_classes))\n",
    "            \n",
    "            if iw == 0:\n",
    "                classes_tensor = class_tensor                \n",
    "            else:                    \n",
    "                classes_tensor = np.concatenate((classes_tensor, class_tensor), axis = 0)\n",
    "                \n",
    "        box_class_tensor= np.concatenate((classes_tensor, boxes_tensor, boxes_tensor), axis = 1)\n",
    "        y_encoded = box_class_tensor\n",
    "        \n",
    "        y_encoded[:, self.background_id] = 1 # All boxes are background boxes by default.\n",
    "        \n",
    "    \n",
    "\n",
    "        gt_one_label = gt_label\n",
    "        m = gt_one_label.shape[0]\n",
    "        if gt_one_label.shape[0] == 0: \n",
    "            return y_encoded# If there is no object, skip\n",
    "\n",
    "        #FInd the iou of ground truth and all anchor boxes\n",
    "        similarities = calc_iou(gt_one_label[:,-4:], y_encoded[:, -4:])            \n",
    "\n",
    "        #Find the highest matching anchor box per each ground truth boxes\n",
    "        matches = match_bipartite_greedy(similarities)\n",
    "\n",
    "        #Convert ground truth class label to one hot encoding            \n",
    "        gt_class = np.array(gt_one_label[:,0], dtype=np.int)\n",
    "\n",
    "        #Fill in y_encoded\n",
    "        y_encoded[matches, :self.n_classes] = class_vector[gt_class]\n",
    "        y_encoded[matches, -8:-4] = gt_one_label[:,1:]\n",
    "\n",
    "        #Set the matched anchor boxes to 0 to indicate they are matched before multi object matching\n",
    "        similarities[:,matches] = 0\n",
    "\n",
    "\n",
    "        #Multi object matching\n",
    "        #Similar process to bipartite matching\n",
    "        matches_anchor, matches_gt = match_multi(similarities, threshold=self.pos_iou_threshold)            \n",
    "        \n",
    "        for i in range(len(matches_anchor)):\n",
    "\n",
    "            y_encoded[matches_anchor[i], :self.n_classes] = class_vector[gt_class[matches_gt[i]]]           \n",
    "            y_encoded[matches_anchor[i], -8:-4] = gt_one_label[matches_gt[i],1:]\n",
    "\n",
    "            #Set the matched anchor boxes to 0 to indicate they are matched before applying negative iou threshold\n",
    "            similarities[:,matches_anchor] = 0\n",
    "\n",
    "        #All background boxes whose iou are greater than neg_iou_threshold \n",
    "        # are set to neutral(neither background nor class)\n",
    "        max_bg_similarities = np.amax(similarities, axis = 0)\n",
    "        neutral_boxes = np.nonzero(max_bg_similarities >= self.neg_iou_threshold)[0]\n",
    "        y_encoded[neutral_boxes, self.background_id] = 0\n",
    "        \n",
    "        y_encoded[:,[-8, -7]] -= y_encoded[:,[-4, -3]] # (cx(gt) - cx(d_box)) # (cy(gt) - cy(d_box))\n",
    "        y_encoded[:,[-8, -7]] /= y_encoded[:,[-2, -1]] # (cx(gt) - cx(d_box)) / w(d_box) # (cy(gt) - cy(d_box)) / h(d_box)\n",
    "        y_encoded[:,[-6, -5]] = np.log(y_encoded[:,[-6, -5]] / y_encoded[:,[-2, -1]]) #log(w(gt) / w(d_box)) #log(h(gt) / h(d_box))\n",
    "                  \n",
    "        return y_encoded[:,:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 646,
     "status": "ok",
     "timestamp": 1613128692930,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "kEs16TML9K_b"
   },
   "outputs": [],
   "source": [
    "ssd_input_ds = SSDInputEncoder_ds(IMG_SIZE, \n",
    "                 IMG_SIZE, \n",
    "                 layer_width=layer_width, \n",
    "                 n_classes=n_classes, \n",
    "                 num_boxes=num_boxes, \n",
    "                 s_max=s_max, \n",
    "                 s_min=s_min, \n",
    "                 aspect_ratio=aspect_ratio, \n",
    "                 pos_iou_threshold=pos_iou_threshold,\n",
    "                 neg_iou_threshold=neg_iou_threshold,\n",
    "                 background_id=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 772,
     "status": "ok",
     "timestamp": 1613128693847,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "dumbQj679K_b"
   },
   "outputs": [],
   "source": [
    "def y_encode_wrapper(image, label):\n",
    "    label_shape = [8732, 15]\n",
    "    [y_encoded] = tf.py_function(ssd_input_ds, [label], [tf.float32])\n",
    "    y_encoded.set_shape(label_shape)\n",
    "    \n",
    "    return image, y_encoded    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 663,
     "status": "ok",
     "timestamp": 1613128695425,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "tgpzJtPf9K_b"
   },
   "outputs": [],
   "source": [
    "ds_train_encoded = ds_train.map(\n",
    "    y_encode_wrapper, \n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "    deterministic=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "executionInfo": {
     "elapsed": 975,
     "status": "ok",
     "timestamp": 1613128697744,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "RSCMom5w9K_b",
    "outputId": "1a33958e-2cc0-408b-8443-9b70ee4cc3dd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/matplotlib/text.py:1165: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if s != self._text:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image, label in ds_train_encoded.take(1):    \n",
    "    show(image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1613128700565,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "zHzENoAC9K_c"
   },
   "outputs": [],
   "source": [
    "ds_train_encoded = ds_train_encoded.batch(32)\n",
    "ds_train_encoded = ds_train_encoded.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6ryGyxx9K_c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dvFHobrU9K_c",
    "outputId": "832f1ecc-2ca9-4615-e014-f6ab9382f868"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAJCCAYAAAA7hTjJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdWYxt2X3f99/ae5+xqu7U80SRoinHJJLQAMEkUAIoAhIJeaH8oIB6kPkghAIiIREgP0gCFPNFgB88BQhsgIYE04BtmYAtiDHkWDI9xYokTpAtDiK72ePt233HqlvjGfbeKw///9r7nFVVfW931+1udX0/gLSrztlnn32qL+/912/911ohxigAAAD0inf7BgAAAN5rKJAAAAAyFEgAAAAZCiQAAIAMBRIAAECGAgkAACDzwAqkEMKPhxC+G0J4LoTwSw/qfQAAAM5aeBDrIIUQSknfk/Q/SLoq6auSfirG+O0zfzMAAIAz9qASpE9Kei7G+HyMcSHpNyV96gG9FwAAwJmqHtB1n5L0ysr3VyX9V6edHEJgOW8AAPBOuxVjfOSkJx5UgRROeGytCAohfFbSZx/Q+wMAANzLS6c98aAKpKuSnln5/mlJ11ZPiDF+XtLnJRIkAADw3vKgepC+KukjIYQPhRCGkj4t6UsP6L0AAADO1ANJkGKMdQjh5yX9S0mlpN+IMX7rQbwXAADAWXsg0/zf9E0wxAYAAN55X48xfuKkJ1hJGwAAIEOBBAAAkKFAAgAAyFAgAQAAZCiQAAAAMhRIAAAAGQokAACADAUSAABAhgIJAAAgQ4EEAACQoUACAADIUCABAABkKJAAAAAyFEgAAAAZCiQAAIAMBRIAAECGAgkAACBDgQQAAJChQAIAAMhQIAEAAGQokAAAADIUSAAAABkKJAAAgAwFEgAAQIYCCQAAIEOBBAAAkKFAAgAAyFAgAQAAZCiQAAAAMhRIAAAAGQokAACADAUSAABAhgIJAAAgQ4EEAACQoUACAADIUCABAABkKJAAAAAyFEgAAAAZCiQAAIAMBRIAAECGAgkAACBDgQQAAJChQAIAAMhQIAEAAGQokAAAADIUSAAAABkKJAAAgAwFEgAAQIYCCQAAIEOBBAAAkKFAAgAAyFAgAQAAZCiQAAAAMhRIAAAAGQokAACADAUSAABAhgIJAAAgQ4EEAACQoUACAADIUCABAABkKJAAAAAyFEgAAAAZCiQAAIAMBRIAAECGAgkAACBDgQQAAJChQAIAAMhQIAEAAGQokAAAADIUSAAAABkKJAAAgAwFEgAAQIYCCQAAIEOBBAAAkKFAAgAAyFAgAQAAZCiQAAAAMhRIAAAAGQokAACADAUSAABAhgIJAAAgQ4EEAACQqd7Oi0MIL0rak9RIqmOMnwghXJH0TyR9UNKLkv7nGOP227tNAACAd85ZJEj/fYzx4zHGT/j3vyTpyzHGj0j6sn8PAADwZ8aDGGL7lKQv+NdfkPQTD+A9AAAAHpi3WyBFSb8bQvh6COGz/thjMcbXJMmPj77N9wAAAHhHva0eJEk/HGO8FkJ4VNLvhRD+9H5f6AXVZ+95IgAAwDvsbSVIMcZrfrwh6bckfVLS9RDCE5LkxxunvPbzMcZPrPQuAQAAvCe85QIphLARQthKX0v6HyV9U9KXJH3GT/uMpN9+uzcJAADwTno7Q2yPSfqtEEK6zj+KMf4/IYSvSvpiCOFnJL0s6Sff/m0CAAC8c0KM8d2+B4UQ3v2bAAAA583XT2v1YSVtAACADAUSAABAhgIJAAAgQ4EEAACQoUACAADIUCABAABkKJAAAAAyFEgAAAAZCiQAAIAMBRIAAECGAgkAACBDgQQAAJChQAIAAMhQIAEAAGQokAAAADIUSAAAABkKJAAAgAwFEgAAQIYCCQAAIEOBBAAAkKFAAgAAyFAgAQAAZCiQAAAAMhRIAAAAGQokAACADAUSAABAhgIJAAAgQ4EEAACQoUACAADIUCABAABkKJAAAAAyFEgAAAAZCiQAAIAMBRIAAECGAgkAACBDgQQAAJChQAIAAMhQIAEAAGQokAAAADIUSAAAABkKJAAAgAwFEgAAQIYCCQAAIEOBBAAAkKFAAgAAyFAgAQAAZCiQAAAAMhRIAAAAGQokAACADAUSAABAhgIJAAAgQ4EEAACQoUACAADIUCABAABkKJAAAAAyFEgAAAAZCiQAAIAMBRIAAECGAgkAACBDgQQAAJChQAIAAMhQIAEAAGQokAAAADIUSAAAABkKJAAAgAwFEgAAQIYCCQAAIEOBBAAAkKFAAgAAyFAgAQAAZCiQAAAAMhRIAAAAGQokAACADAUSAABAhgIJAAAgQ4EEAACQoUACAADIUCABAABkKJAAAAAyFEgAAAAZCiQAAIDMPQukEMJvhBBuhBC+ufLYlRDC74UQnvXj5ZXnfjmE8FwI4bshhB97UDcOAADwoNxPgvT3Jf149tgvSfpyjPEjkr7s3yuE8FFJn5b0MX/N3wkhlGd2twAAAO+AexZIMcZ/L+lO9vCnJH3Bv/6CpJ9Yefw3Y4zzGOMLkp6T9MkzulcAAIB3xFvtQXosxviaJPnxUX/8KUmvrJx31R8DAAD4M6M64+uFEx6LJ54YwmclffaM3x8AAOBte6sJ0vUQwhOS5Mcb/vhVSc+snPe0pGsnXSDG+PkY4ydijJ94i/cAAADwQLzVAulLkj7jX39G0m+vPP7pEMIohPAhSR+R9JW3d4sAAADvrHsOsYUQ/rGkH5H0cAjhqqS/KumvSfpiCOFnJL0s6SclKcb4rRDCFyV9W1It6edijM0DuncAAIAHIsR4YovQO3sTIbz7NwEAAM6br5/W6sNK2gAAABkKJAAAgAwFEgAAQIYCCQAAIEOBBAAAkKFAAgAAyFAgAQAAZCiQAAAAMhRIAAAAGQokAACADAUSAABAhgIJAAAgQ4EEAACQoUACAADIUCABAABkKJAAAAAyFEgAAAAZCiQAAIAMBRIAAECGAgkAACBDgQQAAJChQAIAAMhQIAEAAGQokAAAADIUSAAAABkKJAAAgAwFEgAAQIYCCQAAIEOBBAAAkKFAAgAAyFAgAQAAZCiQAAAAMhRIAAAAGQokAACADAUSAABAhgIJAAAgQ4EEAACQoUACAADIUCABAABkKJAAAAAyFEgAAAAZCiQAAIAMBRIAAECGAgkAACBDgQQAAJChQAIAAMhQIAEAAGQokAAAADIUSAAAABkKJAAAgAwFEgAAQIYCCQAAIEOBBAAAkKFAAgAAyFAgAQAAZCiQAAAAMhRIAAAAGQokAACADAUSAABAhgIJAAAgQ4EEAACQoUACAADIUCABAABkKJAAAAAyFEgAAACZ6t2+Abx3/eqv/hXdff01SdLsYCZJqkYb9mRhtfWH/9yH9YMf/rA9FqMk6dWrr0iSvv3Vr0qSXnz+eTVeihcD+yM3mkwlSZe2LkiSLly82B0vX7ksSbp48Yokabpp329t2TmTzanGU3v9eGL3Uw4nkqRWwY9+S6u/AjR2f21rzxalPfnJj3/0vn8mAIDzgQQJAAAg8/5LkH5B0qV3+ybe43Yk/e17n3b5kSf1yEOPSZI+8PQP2GNXHpYkLcJAkhSqoaInR7PZkSTpzz/+QUnSh/+z/0KS9Pz3vqe723fsre/Y8eWXXpAkvfKyHSsLfjQZDtQsDiVJg6qUJI3HliBVo7F9v7WhydamJOnSQ4/Y8cqTkqSLl+zczYuWTG1dvKDJ5pYkqRxZ6lRW9se+Kst7/xAAAOfS+69AuiTpc+/2TbzHfe7dvgEAAN7b3n8FEs7MD/35v6Bnv/usJOnW3T1J0tT7gEYTS5Bms30Nh0NJUruwBOlgbgnQI48+IUn6b576oF59+UVJ0uHdHXvsh/9bSdJr11+VJA0HI0nSpc0tffM/We/Sv/vy70iSmhvPS5KKwmKmGILKkb1neu+ytecG/n01sutNNya66CnY1pWnJUmXL1tv00MPPfTWfjAAgPc9CiSc6vLWln7wz31EknT1lZckSXfuXJckXUiF0niiYWlDbBtDa2k7mi0kSbGxoqWupYsXbehrMbciqm7snGe8wXsytnHRzeklPfzMhyRJhz5097u/9U8kSWVt3w/LgQatvb49smPRLCVJMy+i2mDHm2oVn7MiT6UPsRU2tDbyIgoAgBxN2gAAABkSJJzqO3/yH3XhoUclSZPKaunt2zckSUee3Dz6+FNS0UiSlj6nfuFJT2jtWLRRA5/ef/myNU///u//G0nS1sRSnI9+7JOSpHk51cIupwuPPG7XrWwK//b2tiRpWrWaljbEN/KG61DZdaLfu7+1YpBi9En/CxsmTE3le4fpbAAA1pEgAQAAZEiQcKo7Ozf1zT/+I0nSoLYU5vEP2XT/hX8/3dzQdGrN2NHrbX9Kh0eW2BSltFzMJUl/+h+/Lkn6xr/9XUnSxoYt9PjEI3aNx56ZaOhp03/+0f9SklT99P8qSXrV+6Du7tzS3q4tF7C/a03fBwcHkqSjI+txWi6Xfk9RIdh9DT2JGg4sfZr6YpN64dab/+EAAN7XSJAAAAAyJEg41YWLF/XC4b4k6dbrNnvtqLVkZuth600KIWgytgUcH3rEFmusKkto5kc23X8yGerZ731HkvQH/+H/lSQVjTUa7dyy9Oaab08y2npIw6kvAukz3/67H/lRe43PUDuaHejw0NKpg727kqTrVy1devEFW3jy2eeek2QJ1dNPP2P359P9JxNLkq5csen+//prP/tWfjwAgPcxEiQAAIAMCRJOV410yRdVvP78i5KksadCu1dftsevX9fXv/ENSdJHvWdoumEz1RZz2+C2CNJ/+sZXJEl3vWeori1BahtrWPKdRhRj1HJhKdV+tL6i1Co0GljyM9m4oIuXLcEaDy2tGhZ23L1r9/ejP2rrKz322GPa9A1xq7FdKG1WO/bkCwCAHAkSAABAhgQJp5rVrYbj9Q1e66Wvku0byb5+7Ya+/4L1D/3BH/yhJKnwNYqq0l7zyJVL0tLSJF9OSXu71kP0kG86O/StQ0JRqGk9XfIFkQYDey5tRNs2rWYzu973vmu9Tb//b/+1JOnFF21bkieffEqSdGv7tqLnU9XYZsxVPout9pluAADkKJBwqksPP6rrz1oBkna+n/kQm4b2R2dQBU1G9vX+oU3lT4VHW1lhs7tzS83MhssuXrItRRa+kuNsbq/Z39/396m0P7PHLvjQWLu0IbHUKH5wsKfvetP3175qyxA8//x37Tm/zgsvfd/ub1CpjVYgFaXv2+afpa7rt/aDAQC8791ziC2E8BshhBshhG+uPPa5EMKrIYQ/9v/7n1ae++UQwnMhhO+GEH7sQd04AADAg3I/CdLfl/R/SfoH2eN/K8b411cfCCF8VNKnJX1M0pOS/lUI4YdijM0Z3CveYc8880F976v/nyTp9l2bTn+0benO0x/8gCSpCEFFYXW27w/bbe3RRkto6kWjjYk1RO/u2dDa3oFdZ+KvTY3eL964qy2f3r8xtSGxYbAhse99708lSds7N/Xii8/617clSY3/EYtpjxG/l6ZplHYaiW3w+/MtUApa8AAAJ7vnvxAxxn8v6c59Xu9Tkn4zxjiPMb4g6TlJn3wb9wcAAPCOezs9SD8fQvjLkr4m6RdjjNuSnpL0hyvnXPXH8GfQtBzriWc+KEla+qay9dz6i+YLS2F2dmdaeo/PwFOi4FP3G+8lqouBYmmvr0bewD23xGfuG9x+81lLhG5//Y81nXjjtjeGR7/+kfc/tbHpUqrSG8Il6ytSEf01nhKVlVR20dbac/3iAgAArHurYwx/V9KHJX1c0muS/oY/ftK/OCdumR5C+GwI4WshhK+9xXsAAAB4IN5SghRjvJ6+DiH8PUn/3L+9KumZlVOflnTtlGt8XtLn/RonFlF4d832DvXUk/afc/OSLRh5dN02g72zbT1JB4fzfjaYbwXSNj6LrbHHF4ra3t2VJA19YceQtg2Z27IB+76o5Hw57xaRLL1+9wBJwXuGihC6xR5Ty1GR/RFqPMUy68+lBCkQIAEATvGWEqQQwhMr3/4lSWmG25ckfTqEMAohfEjSRyR95e3dIgAAwDvrnglSCOEfS/oRSQ+HEK5K+quSfiSE8HHZr+YvSvpZSYoxfiuE8EVJ35ZUS/o5ZrD92TWfHXWLPV6+YDPL6pklSCmUOTw60tAXjTzyxRtbXwep8t6fEKTCe4NmM+sjKoLX5h7jLBaL7n1TwtOmmWkp6vHUaPUPVHeu0sy09J7H46Gu9yj1It3j8wMAzq97Fkgxxp864eFff4Pzf03Sr72dm8J7w+Hhtl7y6fSTsS2yeOnCliRp7kVQsSM98pANv6Ui5+jQiqCFn7NYLFV5EVWWVhgtl74EgA+nNW2aix8VvXRJDykNn4V+mn4qgKKflIbs3kjMC6NIiQQAOBkLwQAAAGTYagSn+spX/51effkFSdKgsrTlYH9HklSNJ5Kkzc1NPf2EtaTdvWPPbTeWCk18aYDtnR2lNRlrb54+OrKtR0pZMnVSmtONkqUvwvpCj9Lpw2Rh5dx4SlJ02uMAAJAgAQAAZEiQcKrvf/ebunPrliTpB3/wByRJI18McrbwKfyLmQaVbzXi7dOlpzd7h9bQHYtSI0+c6gPbaiR6yrRo7TptF+b0vUTdco4hnHi8X6clRWw1AgA4Df9CAAAAZEiQcKpbV19V26Qp9vZHZTK9JEm6cfOqJGlzsqm9/W1J0mBo5858uv+Rz9yfTC/o7l07J9Y2s206sY1od48sSWprn6YfglKKlGaz9a1IbzB13xVFufb4SenRW02iAADnBwkSAABAhgQJp9o9mmk6sJ6j3R2fveY9SFM/Dipp7pvSbk4tFZr5YpLRN7ZdxoVibXFSCnQa/6LutgRJqU7xlmadpedK7ytq/fumOX2d0rZtT30OAHC+kSABAABkSJBwqqPFUqVsltmdW7bn8COPPS5JeurJRyVJ49FQd27bTLdbN29L6jernRZ2HBalHn3SXvf6Ldvkdnt3X9JJCVLfF5T3Ct1PgpRW5E4z1EIIXYqUz1qjBwkAcBoKJJyqPrqrNoWMjRcc0QqmqrJC5PEnHtejDz8mSfoX3/8dSdKTTzwpSZoM7KWHs4UOllak1G3aO82ul/ZoW619TmuiTkNiq1uNpMUAYnbOajGUvk7HN2rgBgBAYogNAADgGBIknOoDD0/10JWpJOnSZUuJBtMLkqRZY03XN2/d0A889WFJ0jNPfUCS9MjDthRA7UNt1771Hd3asQUiFz6iFrohsJTiHE9z8oSnT41Cvw1JGprT6UN1KTkqS1sCoK7rN/7gAIBz7/1XIO1I+ty7fRPvcTvv9g0AAPDe9v4rkP72u30D7x8ffuZhTbc2JUmDDUuFXrpmDdm393YlSYcHC938wB1J0uNP2aa1N2++Lkl6/sVXJEmvvn5TCr6AYzp6L9L9NEqnJKkoVhaQ9F6jfEPbNjb+mjR6HNUtNZm/FT3aAIBT0IMEAACQef8lSDgzGxc3VIwsOTr0WWxtaccqDCVJk1GpvQObun+wPJQkPf/iC5KkO3csZbKZa6lXKJ+yf3xm2bFUyfuUoj9cFUFtmr3mSVK7stCkJC0b6zNqYisPnlT4H/dWp/c9AQAgkSABAAAcQ4KEU118+HG9/JrNPnvptZuSpMbTncWRJTSzo4V2Dmxz2jCwP05zX/PI24xUVVW36W1ap6jb5SOsb/cRY+zSpBQkVWXaPsTXQVKlMBjZ177QZJl6kHxRyLpJiVRQiGnGXOXHNJXu9G1IAADnGwUSTjWvpavXbkiSrr5uBdIiVT2tFR31otZ0w/Zgq2orPJplGv7y5upBIa9t+sUe/T2C1hdxtHPWC6SQzl7ZX60srNk7LRcwTEN15foQXtu2ar2Iahe2Z1zhN1OUDLEBAE7GEBsAAECGBAmnOjo41HJpiz0W3vzcLBf+rKUwVVmo9LSm8kBm6A3T7ciGwRZ1o35OfVw7pJQoTeFvV0bc0mNpEchSvqeaoorGhvVKP2dS2R/lqvJkyZcTqJfLlf3elmv3XpbM8wcAnIwECQAAIEOChFPN9vdUHx1JkkJqhlbqA7Im7RBKxaX19lTF+oKMcTSWJNVxroVv7xGz1Rmb1LTdTfPvn4s+rz9N4U/V/LRqNR3YYxemllJNp/ZehW8nUnmiVBSFYlxfVDI1fQ+GdvzTl+/e188DAHB+kCABAABkSJBwqrae6cqFgSSpqiyFmfs+r7G1hSIH5UDDys4Z+syyprXv73pqNB5Uqse+PIDvVlsv0ywz+Wt8dluM3WKSpc8yG1bWe3Rxw1Kix65c1MWJ/dEdD+09iypN5U+vTT1Jg+6xUER/rvRj+v3gu2/2RwMAeJ8jQQIAAMiQIOFUQUs9csWSokceslSobdNMMuv9KYv+j1C/CKQdLxzajLfBaKObkTaf2et9SaK15CgdC0+ihgOr3ydDm322mfqNJtMu/Sl9HaTCZ6Sl+ymKgd9VYZvb2pda/SKt0wQAQI4CCaeLUZUPXaXjYGDDXINy5CeFrrhpfBXrxcKG1lKxsnVhqjYu/OzSX5cWerTXhNAvHZmGxIqw3pzdLRwZQrfnWj+kNvD39CE3L5BCqPrlAvwY0xUj0/wBACdjiA0AACBDgoRThaLoGpqHQ0tkxmNv2vbEJih0Q2opQYr+/XQwkSQNyqDanwuFLxfgpXmf7hTd9Y6tKXlsUcmyS5cU0oXK7jlJKkL/fdrGpFsYMu3Nxu8HAIBT8C8EAABAJsT47jeqhr4BBQAA4J3y9RjjJ056ggQJAAAgQ4EEAACQoUACAADIUCABAABkKJAAAAAyFEgAAAAZCiQAAIAMBRIAAECGAgkAACBDgQQAAJChQAIAAMhQIAEAAGQokAAAADIUSAAAABkKJAAAgAwFEgAAQIYCCQAAIEOBBAAAkKFAAgAAyFAgAQAAZCiQAAAAMhRIAAAAGQokAACADAUSAABAhgIJAAAgQ4EEAACQoUACAADIUCABAABkKJAAAAAyFEgAAAAZCiQAAIAMBRIAAECGAgkAACBDgQQAAJChQAIAAMhQIAEAAGQokAAAADIUSAAAABkKJAAAgAwFEgAAQIYCCQAAIEOBBAAAkKFAAgAAyFAgAQAAZCiQAAAAMhRIAAAAGQokAACADAUSAABAhgIJAAAgc88CKYTwTAjh34QQvhNC+FYI4X/3x6+EEH4vhPCsHy+vvOaXQwjPhRC+G0L4sQf5AQAAAM7a/SRItaRfjDH+BUn/taSfCyF8VNIvSfpyjPEjkr7s38uf+7Skj0n6cUl/J4RQPoibBwAAeBDuWSDFGF+LMX7Dv96T9B1JT0n6lKQv+GlfkPQT/vWnJP1mjHEeY3xB0nOSPnnWNw4AAPCgvKkepBDCByX9RUl/JOmxGONrkhVRkh71056S9MrKy676YwAAAH8mVPd7YghhU9I/lfQLMcbdEMKpp57wWDzhep+V9Nn7fX8AAIB3yn0lSCGEgaw4+ocxxn/mD18PITzhzz8h6YY/flXSMysvf1rStfyaMcbPxxg/EWP8xFu9eQAAgAfhfmaxBUm/Luk7Mca/ufLUlyR9xr/+jKTfXnn80yGEUQjhQ5I+IukrZ3fLAAAAD9b9DLH9sKSflvQnIYQ/9sd+RdJfk/TFEMLPSHpZ0k9KUozxWyGEL0r6tmwG3M/FGJszv3MAAIAHJMR4rD3onb+JEN79mwAAAOfN109r9WElbQAAgAwFEgAAQIYCCQAAIEOBBAAAkKFAAgAAyFAgAQAAZCiQAAAAMhRIAAAAGQokAACADAUSAABAhgIJAAAgQ4EEAACQoUACAADIUCABAABkKJAAAAAyFEgAAAAZCiQAAIAMBRIAAECGAgkAACBDgQQAAJChQAIAAMhQIAEAAGQokAAAADIUSAAAABkKJAAAgAwFEgAAQIYCCQAAIEOBBAAAkKFAAgAAyFAgAQAAZCiQAAAAMhRIAAAAGQokAACADAUSAABAhgIJAAAgQ4EEAACQoUACAADIVO/2DQB4//jV/+OvSJKWR0eSpKO9XR3t7kmSFvOlJKlt7dyiGvoXpRp/cHNzQ5J05aErkqQnn3xCknT5ykOSpK2tLSlGSdLh4aEkaW9vV5L02iuvSJJuXbum1162r3d379q5s5kkKVSlv7cdQ1moGtp9DIYjSdJkMrXjaCxJ2phuaDiyc8b+3NBfM93Y8MfH2tjclCSNhva60dieqwYj/95fOxhqNB77c6W/t12vrOyv5Go4VFVWaz+nUNi5MdjvtW2Malv7WbSyo/9oFIN/v/p4etJfE/1nHtv+3FAEe69gx09+/KMCzisSJAAAgAwJEoAzU6ZUaOQPtFHDyr4JslSiLAeS+mRFZdUlSKPJRJJ04cIFSdLmJUuSRhtbkqRiMFYb7dxqbNebyJKVK4/WdrmiUgj2V9t0Z1uStH+wb+/lyUi0g6IsidHKsV7adQ6bA0lSs1yoGtg9jw/tsYF/f7Rvn2EwHGji9z4apsQoJUiWFg1H9vygGmo4tnPKgd3nwBOqqkrfjzQYeLLlr0s/28J/fqEoFIpi7XOFsuieW/s+hO7nn6SUyH98Cgr968L6ucB5RIIEAACQIUECcGaGo6l/YanJdDLV2JOQzY1NP17wcz1ZqoZael+SPB1Jz6W+oLL0mENRsa79Oe//uWi/521efliS9NiTz+jhx5+SJN2+dUuSdHfbkqSmbSRJy8VCklTXtfb3LV3a37deqb0961tazqzHKTaL7v0HKeHx7ytPaIoQNfQ0qOtXSglSZQlQNbRjUVZ9YjS0zzvwRKnya4wm065PaTL1n9c49TvZz3Ew6JOoqnvv9L1f19+nLCsFv3cVKTIKqwcVoVBBggR0SJAAAAAyJEgAzsyVRx6TJLW1zVhbzueaeAp08eIlO+eyzUibTi1tGowmqv13tcb7ZNLsrKablmXH5XKpxhuICp+hlWahbWxan1L18KO68ujjkqTHfQbdrvcizXx23YGnRcv5XPu7NgvuwPuUtu/clCTt7d7x1xyo9GRl6CnMyBOatrYkana4r7s7dv5yYTPmvFVKg3K9hygUhQq/TuGz2NJnKHFU/g4AACAASURBVLsEaaJhSpAm9rmGnkBNPEEaDocaTydrrx9Pxt1zkjROP+PhSAOfRVcMUsq0ns4NhgMNqsHaY8B5RoEE4Mw88sijkqTDVGzcuqP9o7kkKRTW4JwKBS99NA1FN+zjdZGW3iidGqfTP9ihbRSbfnhMkppUkIzSNP2JJps2LDX14bzNC1ac7d3dkSSNd+1Yzxe64ksIpEGlw0Mrnna84JnNDlX6lPtu6r8XIvMjG4a7feu6Xn7pOUnS9ddelSTt37WhulHpTeXFwn8OQfLp9N0wV7b8QDUc9g3bqTnbu6krL2KqquoLq2p9uYDh0F47ntqw3Gg81Xjzop0zsgJrnAovH4bbmE419qIsXQc4zxhiAwAAyJAgATgzDz9kacyeD6vVddSeD3PNPBXa9abotCihitClJUqLIPq5KWEpC5/aHlpVskSmaW0Yr2ns+zpN4R9NNfBm8W7K/SRNuffmaB8iW85mUrTG7bGnJk1r731wZInXsq5VefP4xIepNvx6i7kN2d25c0NDH+KTT+tfPP+sJGnuC1oe+fBeURYq0r16btUt0OhDeUVZ9g3TnqIF/5wp6QpFoaJM0/xTAmXfl/541+w+mmjkzd7VMEuQ0hDlxlSTsS9F4M3jwHlGggQAAJAhQQJwZiapd8W34IitTWuX+sbo+dJ6kmazNHU+aJiSHe+vSSlJ6v1JQUkRg4aVP9vYg0vvhi66bTWiGl83YBF9e5Om8euk97T3WYS5mtqem3tjeVn6ApS+7ck0lArBzh95o/TYF2+cbFhfz2TrklpPhVrvl5ot7HO+/vKL9vl9kclhMVBVeJN2N9W+XP8+BqlJDere7e2foeveaoPaNi186U3uHrwtfauRuS9VUBR7CpU1o4fSEq7SF/DsGtCHg+6/Q+ppAs4zEiQAAIAMCRKAM3PgU+bTuo+j0VCbnibVnhwtvLdnNrOj2qWGvrDkeJympa9v3hrTdH/FvjenWF/MsDunlaL36zRxPXVJs+FGvsBiGxsd7Nvssn2fvRb97kc+u2sy3eoXf/TeprLyzWY9iRpvXdDDtX2+vbnNqnv1ms1mu/b6a/64vc+gaTUs7b7ShrSDwu/Pk6AytCpSf5Lfe9eLlBKksLrRbLvyKaXWv0+zAGOUog7ST9DPKlZ/NAohnPqzBc4jEiQAAIAMCRKAM/P6tauSpMoTodHGVtfjkmaJyZOkxo+H9VLLpSUqra/1M/UenbKbTJWSkqgmteT4gpG1fx/SMapLX4r1l3ezxtJms1W1qeXS1zK6k7YcsRRsMrJzLl2cq7hkrxv5tiF1XJ9Bp2XUwj9Dt5WHp19L7xM6mNtrikWtypOikSdQI/+gg9QPVFbdz63sUh1fC2plDaXVTXdPPq48ErOeJk/XYkib9UpNWogqBW/AOUaCBAAAkCFBAnBmbt68Lkkqq7Tp7KTb+LRerCdHMfqUq6LUYpHSDJ/dlWav+awqVX1vTOuxSZckpeQorYfU1GobS2uC/xUXPCXp92D11KRZaP+ubUPy2tUXJUm3brwuqU+QHn/8KZWePE2G1oMUK79e6auCt1GF9zdt+Crejz5mG+Y+9YE7/vnt/paLhdrl0j+Wr/Pk1y+79qKU/EhN6BMjqe/vijGu9Gatfqrjx3S+JIUuQep7mZLuSzarBSiQAJydpe9NdpgasW9cUz2zgqhos+Znn0Y/nE7VeEGz9OJpubRG57axobrCFy4MRdGNpXWjQW3fmpzuId1HGj6qyvXhqXphz+/dvaMbr74sSXr9pRckSTdet+bqsS+yWLbSpS3bquTy5UckSQMf7kp7p8Ugjf1zXbpgU/8/8PQH7d4bO/fSxhX72Rzs6/DAGsIbX1qg9u1SGi+clotZ/5w/1rSpAEyfv1XbpnLJ5ENr0Yuhtl1p9vZzyrQ4ZVqMsyy7pvHUrA2cZ/yvAAAAIEOCBODMpM1Wl4e+We3t6zq4Y0NMpS98OPVp/1sPWaIybS5LvpVIk4aBPPlJ22AMPKkZj6caeoN1jGm7Dv89r01pSaPaE6Ry4AsoespUL+3xO7dvSpJee+VFvfx922T2jidHuzdvSJL2PXWajMZ6+GFLjq48bJvxTlJU4ylMLIIqT122Nmwrj2ee+aAk6fKFhyVJH3jqQ5Kko6ODrhF84cnR4dH+2vdHh/ta+nIBR74h7mI+9++P/NxF9/Xcn0sb+BZp6C4NVVZVvxinN4Snn2NKi0bDoUaemqWtX7767CsCzisSJAAAgAwJEoAzM51aE3NKP8pQdD00S+9FajzlaDzlWESpGlmvUew2py38epY2TcbeizTd0NDP9YOGviHtwpvAY9N0CyemTVvTViOHnmzduGHN5K+88pJu3rDEqPUtR0ZpI1vvAZofHWl/z3qG0sa7rSde0RMaFWW3qGXl77npSdLEF5e8ctk28m3bpuu1WniiNZtbSpQenx0daOl9Uqlfae5blezeveuf5VC3bt2SJN3ZtkbzlCilxG3Df34bm5va8ubxkW+TMvaNabtlGCZjTSb2WEqb/tH//S8EnFckSAAAABkSJABnZuipxNB7WYajUfdb2KGnSqlfpvWkpQ5BpfcazT1tWu2zkaTduzuSpMsP7eviRetdGnkyU3s6lPqLFvO5FnN7fds2fj1LX25ctyn8L734vCTp1auvaGfH0pfSF04MnqikRSDn87lmR3bvs5knNP4ZBiOfLVeUGnj/VKG0sa39DMbj1Efl26eURTfbrPHdZWufxZfut20aRe+pOjqwfqW0HMGt65Z+7exsazq1lOriJfuZLJd2vcnE4rULPqNua2tLFy5eWvu5pSQubZA7Go2616WtXoDzjAQJAAAgQ4IE4My0/jtXkTZxnUw09P6hgx1LQlJqktbwqetac+9LmnkCcnjg/Ta++W3wrUcuX76lRx99QpJ06dJD/pzNNkvrBC0X825j18ND6+3ZTYtBvmpboVx//ZokmyHWpTn+VZP2vO1WWQxdylL4FiEhX0ixjWq8h2m+skGsJFVt2jg39UWV3ev7hR7tM6TNbweTQTfLbD6xPqKB/wxmB0d+73NduHBZknShS9UstdrwXrDNLes7Go/HGk98o11PstJinOm/Q1WVXT9XmsUGnGf8rwDAmVmm3eWD/YM/Gk008qGcbuhq0U/Hl2yxxGUqlnwYbt/rhsXChp4Oj2xIazja6KbcpwIprdodvHhp6rpbCDoVGYc+rf6Wr/R99441N7f1ohuia70pOzWRpwKpKIquAbv0ZQzS1PhuYcYYu+uEVAB6QTT0Y/r8oSxUpf3a/AKlf1+UaY+4SoU/VnvFdnBoP5udu9a0vb2z2w1Bbm5uSZK2fEht05dSmHihVBRlt0dc60tFtjGuHZtlo2Vr71GwkjbAEBsAAECOBAnAmVn4EFm3/UdRdsNGKYVJ233E2G+HkRY2lA9TLefenO3T6lNqsli2ev211yTZPm/2Fmm/taK7bpqqP/Wm49QWPfdm7bS1R1Cf/KTm8ehJUum3NBgMumnzVZW2LEm/W6bFKle29Uh7ndW+rUnhywf4562qqhvKSo3Yiuvbfsznc+35sgWvX7NhwVd9K5QXn/++JOnO9p1u+YKLl2yobeH3fuBLAqQhtxilkLYR8f8eRZe89WlR+gz5Hm/AeUSCBAAAkCFBAnBmCm8ADj7lXqGw/5M1J0v9woQpPWmbWtETpLb1BMq3Cpn7tPqjA1vg8e5e31TdxtQwffw4GXuzsidIo4H3/Pj1B/5+w+FQjfdCLbz3KKYFI8uUDsVu89eUtlRZT1JbN4qemqX+pPQ5fdeUrmlbbVRMfU++lEDqJVr4Mgc72zva3rYtWl560RKja6+8JEl69aod9/f3lJqttrwJ/fb2bUnSeLzebN20bfffoSh9uQFP2dJ/lxhj33+VbYILnEckSAAAABkSJABnZuxbW6Q+njZKjaclaYp8NwMspmn+y26LkZQqFV3CkzaptdRjsay7WV1NF3J4/47P0gqh7Hua1C8lIEmN9/W0RUpTQj/l3o/psrW/Qb2suwUYUwqUtuJIvUR1c9R9rm6D3dTj022ma4dmWXe9Q2lpgP1967Ha3bPZdteuXdX1121Ry5e99+j2LZuBd9s32l3M512v0IEnbNueIFXeM5XuqW3VJUhpyYS0kW1R9r1b6b9VJEECSJAAAAByJEgAzszlhx6WJBWeQOzduqGlpyQpxUmzxebeD1Q2A1Uj713q+pQszRl4j8/QExH7PqUbacbV+j0UoX+w8SQryJMRX6Oo8d8Nl8uFoidQ86Wdo9rXLfLmoaPZTDs7ttXJzZu2sW0d7H4mm7657HzRzWwbj1Pfk6VLaYZa2gx3WS+18PWe0hYj2zuW/Ny5beszvXL15e69btywJCltl3J0ZItftm3b9T2lFCzNEEz5Wb9Ok9T9PpySvBMWvUy9R8xiAyiQAJyhSxdtunnt/4hX1aCbRj/zwmh/34aDGm+CHjUTbXkBNBzasFQqcPJ/xEMIytcw7Buo0yKVUTEVT15L+WW666fovF4uNfeCaDa3YqVI0/G9sXu+WOjOHWuYrl55RZK0vW8FztRXsg5F0e1flobfUoGUVsA+OrCfyfbOtnbu3vH3X/hjViBtb1uBdPPmde0f2LBbGj5rfK+4fhisL2LSzyR93m66fve9ukJtdWmC1S/sGmH1FOBcY4gNAAAgQ4IE4MxsbdiWFzM/bmxuqfStRpYecxx4atJ4chOHhaZpaKf1xRW9ETs1SndhSSjku5ioSDHHsdGgfugp7asWi/W9zlLi0tRNtzdc2sstDblFj50O50s1tyzh2Tmyey+GtnjjaGqfczQad0NrVZmGA31fNU+QDvZtiOz2ndva2bEEqfEhtv2DXT/Hj4f7/Z51SkN+64tJrumWEvDtQ/KhsrgyFJktO7A6nJaaukmQABIkAACAY0iQAJyZ0vtcRr4Y4cbmBU0v2I7ywRuxm8qnlactR4qyW/Sxrn1LkHnqW7IUZelRUCyKLuWoCk9L/L3Toouxabpp6rHbVNaPIW0K683goVXlF6j8PdLCjvLkZ9G0mh9a/9Bi346pbymdMxqONfIp/6X3VqUNaNM0/7Tx7tHhgWbepB29ryg1a6dG9qhCRWU/r/632Ljy//2rqLXHUh9WEY7Faisd237IGrGjpEB0BHRIkAAAADIkSADOTOvJT+XJysULl3Txik39H25av458tpfSrKwYNV9YcuIBio6O0vR5T5A8sbH1DrMp7Wmqe9v336QNY33iftfLtPCp9uVKUpIWmEypktIWKH7ObFl325DsHdnWJ/tHPk3f72s4GGpQ+gy5rFcoBTVt1x/U9OlNmjTWvca+L4pCZbewY+q18s+ZkqRoM/bs6xQLrU/wX+tXyub+r15n9WkAhgQJAAAgc88EKYTwjKR/IOlx2S9wn48x/p8hhM9J+l8k3fRTfyXG+Dv+ml+W9DOyX+D+txjjv3wA9w7gPWYx894a7+eZjKe6sGU9SBPfhqTydYJq35C2rhvN/HXBF2BM/TrdFiErW2CkTWmTtOZPP3OrPZYCLX3ByDRTrarsukVZdulLClvaNMPNN7FtY9QyvX9an8lTnW6bDsUuteoTmfX1hrpwpwgqlNZ3Wv/5pevH2CdOIa3ldHy6Xt9P1K4nSd26SF2f0Ukz3/Kept6JM+WAc+Z+hthqSb8YY/xGCGFL0tdDCL/nz/2tGONfXz05hPBRSZ+W9DFJT0r6VyGEH4qpGxEAAOA97p4FUozxNUmv+dd7IYTvSHrqDV7yKUm/GWOcS3ohhPCcpE9K+oMzuF8A72Fz7x1Kc8tGw5E2vfdoY2NTkjSeWJK0mPtGqnXdrXOUtgKpvVcopTh9j03sNnpd7emx1/rvYGn56JX7SBvbppSn9d/Xirbokp527XVSm9ZSahvVvlltWhW8S11WkpqUcvXrVacEyc9OPVOhWAl01vuL4soxxpQyra8U3l0/hFO3BDn+8PHz+nPYVgQ4yZtq0g4hfFDSX5T0R5J+WNLPhxD+sqSvyVKmbVnx9IcrL7uqNy6oALxPpMUNiyJNNw+qvHk5bb0xGdqCimV6TVl3iyvW2b5taaTHR7LUtlGNVzvdlPhsUcRCfaN0KifSkFEaGktz+Zu6VtfQ7Of225v0nysVYWkYT9kwWgj9BPmQFx7deFc6xDcc3lp517XP0A2fpUdPmMp/P0Njx4bhVrYsUVh/L+A8u+8m7RDCpqR/KukXYoy7kv6upA9L+rgsYfob6dQTXn7sf20hhM+GEL4WQvjam75rAACAB+i+EqQQwkBWHP3DGOM/k6QY4/WV5/+epH/u316V9MzKy5+WdC2/Zozx85I+76/n1xXgfaBp+sZrSYrzWgvfpLb0RRs3plNJ0rAq/dxl13g993PndpkuOSoLS6HKsuySo/TbXZfqtGlLDqlPXeyptINGnyD5S2K/LUm/c8n6ioqxjd17dO/lVhObY6FLliTFlRPv9RfeWhKUXzicct6bdGJKFLPUCzjH7pkgBftf4K9L+k6M8W+uPP7Eyml/SdI3/esvSfp0CGEUQviQpI9I+srZ3TIAAMCDdT8J0g9L+mlJfxJC+GN/7Fck/VQI4eOyX4xelPSzkhRj/FYI4YuSvi2bAfdzzGADzgtLWJZLm7Z/eLCnvb27kvrp+KORb8nhv57Vy6JLVNJ0/CQlJENfGiAUoWuGXi596r5/33iy1J6Q+PQ9SOv9RcVKo3Nq+k7z/Ntu4cnYPddlS2/QBJ1vCtt/mGNfHEtxQj8/f/XBEy9zVlPxT0yz6EEC7msW23/QyX1Fv/MGr/k1Sb/2Nu4LAADgXcNWIwDOzO07r0uSDg/2JUk727d1+5a1Ky7mttFrlXb0qPvp6yFtQFulo2//ESxt2tiwpQEGVdUlR6m3abGwhqX0eFTU0tOk5TKlSqv9SSu9SArdrLi0TEDbbVpr99Ksbg1y2rR6hX7S2mnhyxus2didstoDdFq69BaDo5gvJfDWLgOcG2w1AgAAkCFBAnBmrl17SZJ0eHggyRKkg70dezJtTtv4TLWZJUrLulblG9gGb0yqBvZXUzm0JGlr0xaZHFSV5r5RbMiSn5S4FGXRbwHiydEypgRpPcaJit0aR6n/qfUNaEvf9iTGeDzN8WNcm1KmE8/pH+h2pj11naH1zWXvPyrK+5HuZx2jbO/a+34dcF5QIAE4M6+88rwk6cgLpLvb22p96v/mxkTS6i7yafHFZmUfs/Vp9GmobTKxxSVHVSWlJu2ZPdcUdoxF2rQsHBuOSkNqZVn6KfZ907bdezeNN317gZT2TmvjSQXN8eLl1HJmpTDqH7p3QdOVcqdcOMb7r6FsZW6KH+DNYIgNAAAgQ4IE4Mzc3b4tSZrNjiRJe7t3u+n8GxNruK4GpR9t8cdmJdlo6jSF31KnMu1flrYDCaFLmWJcb7xOw2DLZa1FWgIgLQJZpvccrr0mLhfqtvTwc6MP3bVF2rctqM3Cl5OymPvowV75DKc0YK8+do/r3Os9pDc/ZHZWSwcA7wckSAAAABkSJABnZufmDUn91PvDg0ONx9Y/lNqLqtJSnNHYN52N0mJR++vs2G8Ga1J/UFtKQZYydQ3XMW1ea4/P60aL1MrkG+WmHqTUVN2mxSWbtguQ0lYorS9DEL0JqYlduNQ91sdWKeFaWfwx+5mctLDjffUgdZvTrm+w22/Ae3ric2xK/30mSel6JEkACRIAAMAxJEgAzszRvi0QmXqJ2kWtMEwNP/b7WFFYgjQY+PYf86bbpHY5twSp8s1pB5X9FVXXlkjNQyN5b1CRFpzspunbcdFEtT5Ff1ilv+IsQVks7H1q73GKTd1FPgNPm1K/06JbPaBdn86vPtXpk6PVBOnkhRhXk6Q30xuUrhfye1iZrfdmk6L8Oid9DZx3JEgAAAAZEiQAZ+Zw39Y/6nbmaKToW3c0i5W+H0khpI1jS/l6jt3rKk9+Sj8nzWpTLFSV/pxPj0ub1aa+p7qVoqdLqtJij+36OZ5YBUUVnpqUHkl1k+I8mWpj6BKklM8UWYL0QFcYSj/LYz1I4dTEJ22twtpHwFtHgQTgzCxS8eP/iBeh6P6RTkXOYmbFicp+5/rKp+G3XtCkoqX1xSTrpV2jLAaqhl4g+blpocdu2Cz2xU0d1pcEaH217PR8KPrip/X7bNvsGGNXuB0bUgv9Z7jfKunNFi1dWZS9LITQ/ZzSU83bLIjezlAd8H7DEBsAAECGBAnAmZl5o3Ra4HEQpKU3WB8eWgO3Cksn0v5rZQia+iKS45E1SleeLoVoTdt12ietid10/nppzy392Pr7BElFm4bv/H48oSp9kcqmSsNzsRvyqz0xWjZp6xFPn9ZWiTx5GnwIoWum7pYoeIMp828lqemvv3L0pQlOWkogv/79NGCTHAE9EiQAAIAMCRKAM9Nke3IURa1lPZMkHR359HxPkMbRNq8dTaaqpraYZOkN2ClBStP7Z0eHkqTFfK6jI+thOjyw7UyWXe+RpUXFSuN15bczrCyZGo7tPRvPXA6P5jrw6zUpkfLNaps2bTWy+nmOJ0f23seTmjOfMr8eUKmNUeGULUvyY9u2/cKTb3B/TPMHeiRIAAAAGRIkAGcmpTmtp0ShkJbB+odCtOe8DUiDyme6TcYaDO3ByXQqSRqPrCcppR6zI0uLtu/c0c72tiRp35cUSDPLNiaWQlUh9pvceo/OYJQSJLvuwrcMmS9bRdl9+WoEXQq2mhyd1HN02vf3SmFijG+y1yeuHVf7l/JU6H7uIU+Q6DsCTkaCBAAAkCFBAnBm6oUlPelXr6bst/1og6U4MaZ0qOmO0WerlZ4qTbwnaTi0Y7t1wa6/bHTzxm1J0mxuyc94ZLPhJhuWPlVFVGoVSuFIGyyhSmse1ct+0cqY9fYo7+MpTljjaH3NxrXzT/v+jTakPfk168/F/PgGCdJJ1z2t92j1e9IkoEeCBAAAkCFBAnBmRr6R7MD/ZhkNgjbG9nvYyPuANsae+Pg6SIOqVAhpg1dPlTwnGXkv0mjTkqSjg7mGw2uSpOHQnrt06ZIk6eJmnyAtl9b3dOi9S/tH66t4H/qmuIvlslt9OnZrHKU1lOzxQiuBUUpb3qDN6P7WGzr2qpOulM4+8ZwYdSzZOu29VxOkolj/vZjVs4GTUSABODMXJvZXynBg/whPxqU2N3w6/8gKmMnGlp0z2pAklaORam/qrmsrXI58Wv9oaK+dju3cjY1NXfDhtujnXrl8WZK05QVSUUj7+7Yo5Z5P4U9T+WcLv75P6W/a2G0x0g2tpcUXY9qmpN9R5H688bDZ2ltJMduyJH9+/cL23Oo5pzZcr2+JEsLp0/spkICTMcQGAACQIUECcGYevWQpTjdtf1xpY9PSny4xGtixiXbOvF5o3tiQWOPJ0Y52JEmHB7bIZL3wobdGunDBEqRBZa+fekN38MUlF3WtPR9S29mf+dGuu/RtStJ2IgqFWqX0JfswoU9f3k66cjxRkvrNbv0crX27fv6xL9J1V7YfOfaa1LzdX/mBLWAJvE+RIAEAAGRIkACcmcsXrGeoqrwXaVxp7Is/Dsd2XPpGsgcH1he0ezjTvLHE52huSVLagHZnvGfn7loCdGHrkoY+rb/yFSdrX5xyZ9fO3ds/0K3bdyRJ23fv2uuPLEmSN2DHlThmddr86iN9i3R4Uz1IuROn3Bfdk/nJ/t5949PKEpRafyAqdn1Sb3yD4aRv8vtS3xIFgAQJAADgGBIkAGfmwpYlSIVvDjsYDlX5DLTSF31czL0PqLVUZzafaeYpUNqIdu6LQC6OLElqfR+Qpmm1dcFmwaX0ZGd/V5J089YtSdLd3T1t71iaNJvZeywbe8+ysL/yQuH7nYQ+RemSnmwmmPUgvfmfxakz+cPKLLWUEvln6Xekjf2bZk1IK3fcJUdt93rTKiVL/TXycOi0tS8BGBIkAACADAkSgDNTeF9Q6T1IxWAsldYz1Kj0o2cVZdGdO/AApB34U749SVnZa8tuhtpce7ZHrWYLS4fu3LF+o1vbdjw6nGu2sCSqydY4SjlLSL0+8XiC1D1yQqTyRrPZwgkJz6kXSos2ZushxXZ1TaL1PVD6jKhfOyn6o21qHsrWNIrreVN2VyF7nAwJWEWBBODMTHxKf0z7r2moI+u7XlnF2obP0qKNdVz5B96LqG7hQ68K5ouFn7urMLNrH85sley7u7YkwO6BLQ65mNeqfRp/6IbJ8tWj/ai4+s3qoZ+CH+9zMcW8+Xl9rcZuWC2utIiH/MmuYiqOFTldAdZdJ6hN99y2azffntCAfbzZO13PG9fDSa3rwPnFEBsAAECGBAnAmZlu2iKOHg7pcBa1f2hDYemYEqTW44q6btV4E/WytiSk8QUdm2gXCguLoUJVqihLfw97rG7SoogpfWpXAhnfNqRbDHL9KJ0w9NQ9d3qKcmKSlCVH6T2LfP+22PZpVcgSru4YleKhtOjjsbUG2lbH+srTZ8liMLuXdO1y7XaCVveeyxvDgfOLBAkAACBDggTgzFS+IW1a+PFwfqjb2zbl/u7evj9mzxW+VUhUULTASPWy8aNP708pivfmFGWp4K9rvO+mrtcXS4xaaelJG896MpNadeSpUxvjSn+RutdLK/1BOn17jtUkKW/uTtt89Nfpk6r0uvT5ivSrane/1hO0er0uiUr3G8KxXqNjKwOs7GXSfb42u6+YlhoIfch04qcFzhcSJAAAgAwJEoAzk/aAnXsSdHBwpF1PjvYObLuQg7nNZgtF2vaj6BqS2jqlQt575FlGNbT5/1UoVNRparsf0wSuNEW+jcpm9/cbtR7rNzqeHB3XzwHrk6T1hRlXg5z+PdMD61uXrJ/fJ1lr54SgvPWoWOsnsh9Z6D9J9rlSr9VKwtWkpM03/u0+Sr9IZbf8QTj9pwGcFyRIAAAAGRIkAGdm6bPPFr7p7OHRTIeHaUsR6z2az+y5NqUns50OJwAAC8FJREFUCt1MqhTMtN3WINZvVDTer1TGfkHDlHakPp6YZo0VUlhPeE5bm8i268jSkmxrjxBC18PUn5sSmv463auySWv52kJhbRHIsPpUf9uh6B5Mv8WW/lXZLZUUVvqe1hOjvMepbaNSo1fa1qRvcepnyx2/Z+D8okACcGZqn46fhsjatp9yX/qQWuEraKchH7Xqh6H85HRu6eemBuVCaSlJK6wkqfTioPRzBmWpJi2CmM5NK06+me3quyGucGzvtNRUvjYwl++v1hVK68NgRVcarry0K/b8wqHpLpc+V+nVU9U1coeueb0r2No07GjXa7oiNK4UQuv33j0e4sowHgCG2AAAADIkSADOzGJuw2l12gttuVTbrG+DkYbCmi5YadcWbpSkwn93K7qhJx8WapquSbnMkpkuWSlC13icthxpT9mKY2Ww69gaiWmafYzx+DYkmajTU5f8+nGlGbpPxuL6MQSVRZ+ISVJVpu895SmKlWUM0lBdufZ527boPm8/PJhvQ5KWUpCKYr0Z/YXX9k75VMD7HwkSAABAhgQJwJlp0qay3XGpNi366A3csc3imBgVY5qC7o+F9envjT9fqv+tLqUvKV1Kj8ei7BKo0Nb+Vv0SAJLUdEsCrE/RX7uHro+6tUUUpbUNbO3YP5BPse/6rbsL9xvwFit9P5JUpT4tPw7LokuKRkP7LANfILOq/K/tELoE6ViS1N1LSsFaHUuOUnqVlhEog8pyPUGSbgk4r0iQAAAAMiRIAM5M6j2KvpFsqUaDMqUY6xvFVqkXqQ2K/VqFkvp0qMoSkmEZNCjXz2l9Cn7tr62Lopv63y946ImUzwQLvpluDHElBfJDNv09e3BNP4es70Lq0qG156TC76WogobeVzSq7N4ng8I/r71mPCg18sRoOLS/piv/vlzZoqVPkPy907IIK1uW2O2fsAxBtqFvuZogFetJFHAekSABAABkSJAAnJnW1/EJntQMB4WmI09ASl/8sUx9RakfqOgSpL4vxvttPBFJ6yINyrJ7LK3Zk2ZqLf16c8VuilzXr5TO9es0Rb9NSVp6KPUntV3olNZSiv2st3wz2JWFI7vZYN2Clf26R/b5o3+GQhtj2zplOhpKkjb9+6EnOONB0c1aS8lRWJm9lvQ/r7TG1HqClB5fvel+1lp6bdoIuDg2iw04z0iQAAAAMiRIAM5MbL33yBOayahQkKUjy9bSjbTKdtOt2ROVflfr1j/qkiNPRLrVpItu1lW/KrYlIgtf82jWtJqnRbrjwN/D/6pLqVXTH2tvXmqbdFy9qt1fvoVH35/UbyDbpTlFWg3cZ94VdkHfb1ejQaXNyViSNJ2M7Di2o09Y06AqunWQ0vVOWqk7bYGSjunn1n2/1nCU4q/1BKm/Rv8ZyI8ACiQAZyjKioHCV3gcjUI3LT0VFa0XSm3aVT4GhZj+YU8FUTZEtFoj5HuI+fcL379tsJTGacgua2JOBUDaiqNetqqXqViSH9eH09qVvdNiNtSWhFCsFEbecF2moTUrCEcDe344qDRJBdFg2D1mr+2LoiLkBVJqPO8LmjQUmRdKx3eCi309mW3rsnZu/sGAc4whNgAAgAwJEoCz493WKfQYVkHB5+UfCzfSrvIqFIL9VVT4X0ndUE/aHHZliKtdW/xQXaI0WHpTc9nvSz8YrU+RD2E9AWrqqCYNsbVp2YH1+1ub7q83SpDW06q0vEEaYkvLE1RVqYGnamXpn9uHxrqkLIRuS5VulKxrqu7Tov7r9Hr/IXcN5qs3mXWYZwlSjH2CRJAEkCABAAAcQ4IE4OzkyUOhtaZiabUfqG8sLkNKjso3vK4lSP0UfTt6UtOmLTmk4InM2KfRV74QY+z6nlLsFBRjei5vTU6NTK1Ot9owvZ56pW1D0rT6MrVThXDsZ9DPqj8+zb5v/s4asVcWigzpd90upju+9UjIfx0+KUFKSJAAEiQAAIAcCRLw/7d3N6FSlXEcx3+/O6MurIUhiZmUhC2ihYW4EcJNrxtrUegiDIJaKNSul00uJaptUCQYlCKU5Ko3CNqVL0i+YUlJmaKIi7JF4b3/FvOcmTPPzFz0Op5z7vj9bGbOc+bO/c+fZ5g/z8s5GL/SqFG+NqfdLm5tUTy21HL/LrZCZIthIma6Iz5X081vp6f7bwvbdru7tmfRos7e+nTYvUltd/2Tp0r/s380x93dXtHb+ZVvgC+P0GTPBrbKlz9K/jZZQ/8IUoprKt+xNmwXW/5ZeiNS+VqmwZ1uLsXIRn+AESQAAIAMI0gAxidbh9NZbzM4YiSVR5JagyMh6e3y6w5FeLAtLUZqF+t6Fi5QeyrtXivW6HTXHqWdaenYmumNFBUXqezGUIwgqW+kqHNuYAioJLuxbb6exyrtUBt+a4/OcXfIp2hMD6XRoWHXMhryvv3rnrr/JMXX+1sPjCoBty4KJABjM+yHefBqz/2PrVard25gULv/Ao0zM1PdbfdTM8U0Wf8FFdtuda/AXSyULmqUqeJilSouMdArCoqZpyllhYRK5cKoK02XG7L6aJi+C1yXPkOvdum9YWQvLh/2/i7Pe/a+pYKre05ZEOHS56NAAphiAwAAyDhfBFlLEMUYNwAAQHUORcTaYScYQQIAAMhQIAEAAGQokAAAADIUSAAAABkKJAAAgAwFEgAAQIYCCQAAIEOBBAAAkKFAAgAAyFAgAQAAZCiQAAAAMhRIAAAAGQokAACADAUSAABAhgIJAAAgQ4EEAACQoUACAADIUCABAABkKJAAAAAyFEgAAAAZCiQAAIBMu+4AkkuS/kmPuPmWilxXgTxXh1xXh1xXgzxX455RJxwRVQYyku2DEbG27jhuBeS6GuS5OuS6OuS6GuS5fkyxAQAAZCiQAAAAMk0qkD6oO4BbCLmuBnmuDrmuDrmuBnmuWWPWIAEAADRFk0aQAAAAGqERBZLtJ2yfsn3a9ut1xzNJbJ+xfdT2EdsHU9sdtr+x/Ut6XFJ3nPOR7Z22L9o+VmobmVvbb6Q+fsr24/VEPT+NyPV223+mvn3E9lOlc+R6DmyvtP2d7ZO2j9t+JbXTr8doljzTpxuk9ik22y1JP0t6VNJZSQckbY6IE7UGNiFsn5G0NiIuldrelnQ5InakgnRJRLxWV4zzle1HJF2R9HFEPJjahubW9gOSdktaJ+kuSd9Kuj8ipmsKf14Zkevtkq5ExDvZa8n1HNleLml5RBy2fbukQ5KelvSC6NdjM0uenxN9ujGaMIK0TtLpiPg1Iv6TtEfSxppjmnQbJe1Kz3ep88XEdYqI7yVdzppH5XajpD0R8W9E/CbptDp9H9dgRK5HIddzFBHnI+Jwev63pJOSVoh+PVaz5HkU8lyDJhRIKyT9UTo+q9k7Cq5PSPra9iHbL6W2ZRFxXup8USXdWVt0k2dUbunnN8c22z+lKbhi2odcj4HteyU9JOkH0a9vmizPEn26MZpQIHlIG1vrxmd9RDws6UlJW9NUBapHPx+/9yXdJ2mNpPOS3k3t5PoG2b5N0meSXo2Iv2Z76ZA2cn2NhuSZPt0gTSiQzkpaWTq+W9K5mmKZOBFxLj1elLRPnWHZC2kOvJgLv1hfhBNnVG7p52MWERciYjoiZiR9qN6UA7m+AbYXqPOj/UlEfJ6a6ddjNizP9OlmaUKBdEDSaturbC+UtEnS/ppjmgi2F6cFgLK9WNJjko6pk98t6WVbJH1RT4QTaVRu90vaZHuR7VWSVkv6sYb4Jkbxg508o07flsj1nNm2pI8knYyI90qn6NdjNCrP9OlmadcdQERctb1N0leSWpJ2RsTxmsOaFMsk7et8F9WW9GlEfGn7gKS9tl+U9LukZ2uMcd6yvVvSBklLbZ+V9JakHRqS24g4bnuvpBOSrkrayg6Uazci1xtsr1FnquGMpJclcn2D1kt6XtJR20dS25uiX4/bqDxvpk83R+3b/AEAAJqmCVNsAAAAjUKBBAAAkKFAAgAAyFAgAQAAZCiQAAAAMhRIAAAAGQokAACADAUSAABA5n+0MOOjH9h9MwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "i = 9\n",
    "n = 8605\n",
    "\n",
    "fig,ax = plt.subplots(1, figsize=(10,10))\n",
    "ax.imshow(x_train_od[i])\n",
    "\n",
    "box = y_train_encoded[i,n,-4:]\n",
    "rect = patches.Rectangle((box[1],box[0]),box[3] - box[1], box[2] - box[0],linewidth=1,edgecolor='g',facecolor='none')\n",
    "#rect = patches.Rectangle((box[0] - box[2]/2, box[1] - box[3]/2),box[2], box[3],linewidth=1,edgecolor='g',facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 651,
     "status": "ok",
     "timestamp": 1613128705291,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "gZt4vx069K_c"
   },
   "outputs": [],
   "source": [
    "def MobileNetSSD(input_shape,\n",
    "                classes,\n",
    "                alpha=1.0):\n",
    "        \n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    #300x300\n",
    "    x = layers.Conv2D(64, kernel_size=3, padding='same', use_bias=False, activation='relu')(inputs)\n",
    "    x = layers.Conv2D(64, kernel_size=3, padding='same', use_bias=False, activation='relu')(x)\n",
    "    x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same')(x)\n",
    "\n",
    "    #150x150\n",
    "    x = layers.Conv2D(128, kernel_size=3, padding='same', use_bias=False, activation='relu')(x)\n",
    "    x = layers.Conv2D(128, kernel_size=3, padding='same', use_bias=False, activation='relu')(x)\n",
    "    x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same')(x)\n",
    "\n",
    "    #75x75\n",
    "    x = layers.Conv2D(256, kernel_size=3, padding='same', use_bias=False, activation='relu')(x)\n",
    "    x = layers.Conv2D(256, kernel_size=3, padding='same', use_bias=False, activation='relu')(x)\n",
    "    x = layers.Conv2D(256, kernel_size=3, padding='same', use_bias=False, activation='relu')(x)\n",
    "    x = layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same')(x)\n",
    "\n",
    "    #38x38\n",
    "    x = layers.Conv2D(512, kernel_size=3, padding='same', use_bias=False, activation='relu')(x)\n",
    "    x = layers.Conv2D(512, kernel_size=3, padding='same', use_bias=False, activation='relu')(x)\n",
    "    x = layers.Conv2D(512, kernel_size=3, padding='same', use_bias=False, activation='relu')(x)    \n",
    "    \n",
    "    classifier_1 = layers.Conv2D(4 * (classes + 4), kernel_size = 3, padding='same', use_bias=False, name='classifier_1')(x)\n",
    "\n",
    "    #19x19    \n",
    "    x = layers.Conv2D(1024, kernel_size=3, strides=2, padding='same', use_bias=False, activation='relu')(x)\n",
    "    x = layers.Conv2D(1024, kernel_size=1, padding='same', use_bias=False, activation='relu')(x)\n",
    "    \n",
    "    classifier_2 = layers.Conv2D(6 * (classes + 4), kernel_size = 3, padding='same', use_bias=False, name='classifier_2')(x)\n",
    "        \n",
    "    x = layers.Conv2D(256, kernel_size=1, padding='same', use_bias=False, activation='relu')(x)\n",
    "    x = layers.Conv2D(512, kernel_size=3, strides=2, padding='same', use_bias=False, activation='relu')(x) #10x10\n",
    "    \n",
    "    classifier_3 = layers.Conv2D(6 * (classes + 4), kernel_size = 3, padding='same', use_bias=False, name='classifier_3')(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, kernel_size=1, padding='same', use_bias=False, activation='relu')(x)\n",
    "    x = layers.Conv2D(256, kernel_size=3, strides=2, padding='same', use_bias=False, activation='relu')(x) # 5x5\n",
    "    \n",
    "    classifier_4 = layers.Conv2D(6 * (classes + 4), kernel_size = 3, padding='same', use_bias=False, name='classifier_4')(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, kernel_size=1, padding='same', use_bias=False, activation='relu')(x)\n",
    "    x = layers.Conv2D(256, kernel_size=3, strides=2, padding='same', use_bias=False, activation='relu')(x) # 3x3\n",
    "    \n",
    "    classifier_5 = layers.Conv2D(4 * (classes + 4), kernel_size = 3, padding='same', use_bias=False, name='classifier_5')(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, kernel_size=1, padding='same', use_bias=False, activation='relu')(x)\n",
    "    #x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n",
    "    x = layers.Conv2D(256, kernel_size=3, strides=2, padding='valid', use_bias=False, activation='relu')(x) # 1x1\n",
    "    \n",
    "    classifier_6 = layers.Conv2D(4 * (classes + 4), kernel_size = 3, padding='same', use_bias=False, name='classifier_6')(x)\n",
    "    \n",
    "    #Flatten classifiers? and concatenate?\n",
    "    #classifier_1 = layers.Flatten()(classifier_1)\n",
    "    #classifier_2 = layers.Flatten()(classifier_2)\n",
    "    #classifier_3 = layers.Flatten()(classifier_3)\n",
    "    #classifier_4 = layers.Flatten()(classifier_4)\n",
    "    #classifier_5 = layers.Flatten()(classifier_5)\n",
    "    #classifier_6 = layers.Flatten()(classifier_6)\n",
    "    #detections = layers.concatenate([classifier_1, classifier_2, classifier_3, classifier_4, classifier_5, classifier_6])\n",
    "    \n",
    "    B = 1 #classifier_1.shape[0]\n",
    "    \n",
    "    classifier_1 = layers.Reshape((layer_width[0]*layer_width[0]*num_boxes[0], classes+4))(classifier_1)\n",
    "    classifier_2 = layers.Reshape((layer_width[1]*layer_width[1]*num_boxes[1], classes+4))(classifier_2)\n",
    "    classifier_3 = layers.Reshape((layer_width[2]*layer_width[2]*num_boxes[2], classes+4))(classifier_3)\n",
    "    classifier_4 = layers.Reshape((layer_width[3]*layer_width[3]*num_boxes[3], classes+4))(classifier_4)\n",
    "    classifier_5 = layers.Reshape((layer_width[4]*layer_width[4]*num_boxes[4], classes+4))(classifier_5)\n",
    "    classifier_6 = layers.Reshape((layer_width[5]*layer_width[5]*num_boxes[5], classes+4))(classifier_6)\n",
    "    \n",
    "    detections = layers.concatenate([classifier_1, classifier_2, classifier_3, classifier_4, classifier_5, classifier_6], axis=-2)\n",
    "\n",
    "    outputs = detections\n",
    "\n",
    "    \n",
    "    return Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 960,
     "status": "ok",
     "timestamp": 1613128707023,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "pxRDrrRg9K_c"
   },
   "outputs": [],
   "source": [
    "model = MobileNetSSD((IMG_SIZE, IMG_SIZE,3), classes=n_classes+1, alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 761,
     "status": "ok",
     "timestamp": 1613128707697,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "oqTbjsC59K_c",
    "outputId": "3bf49e90-e653-43f6-9b21-5f094d7dd472"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 300, 300, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 300, 300, 64) 1728        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 300, 300, 64) 36864       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 150, 150, 64) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 150, 150, 128 73728       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 150, 150, 128 147456      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 75, 75, 128)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 75, 75, 256)  294912      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 75, 75, 256)  589824      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 75, 75, 256)  589824      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 38, 38, 256)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 38, 38, 512)  1179648     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 38, 38, 512)  2359296     conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 38, 38, 512)  2359296     conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 19, 19, 1024) 4718592     conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 19, 19, 1024) 1048576     conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 19, 19, 256)  262144      conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 10, 10, 512)  1179648     conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 10, 10, 128)  65536       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 5, 5, 256)    294912      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 5, 5, 128)    32768       conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 3, 3, 256)    294912      conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 3, 3, 128)    32768       conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 1, 1, 256)    294912      conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "classifier_1 (Conv2D)           (None, 38, 38, 60)   276480      conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "classifier_2 (Conv2D)           (None, 19, 19, 90)   829440      conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "classifier_3 (Conv2D)           (None, 10, 10, 90)   414720      conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "classifier_4 (Conv2D)           (None, 5, 5, 90)     207360      conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "classifier_5 (Conv2D)           (None, 3, 3, 60)     138240      conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "classifier_6 (Conv2D)           (None, 1, 1, 60)     138240      conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 5776, 15)     0           classifier_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 2166, 15)     0           classifier_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 600, 15)      0           classifier_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 150, 15)      0           classifier_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 36, 15)       0           classifier_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 4, 15)        0           classifier_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8732, 15)     0           reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,861,824\n",
      "Trainable params: 17,861,824\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4_tcu2V9K_d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ghztYQq9K_d"
   },
   "source": [
    "## Model compile and Training\n",
    "이제 위에서 작성한 코드를 이용하여 모델을 생성하고 컴파일하자. 지금까지 배운 Tensorflow API들을 활용하면 쉽게 처리할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 612,
     "status": "ok",
     "timestamp": 1613128711349,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "GKKWxzT39K_d"
   },
   "outputs": [],
   "source": [
    "log_dir = './'\n",
    "model_name = 'mobilenetv2'\n",
    "model_csv_path  = os.path.join(log_dir, (model_name + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 682,
     "status": "ok",
     "timestamp": 1613128711667,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "_0JiXYHw9K_d"
   },
   "outputs": [],
   "source": [
    "class SSDLoss():\n",
    "    def __init__(self, neg_pos_ratio=3, n_neg_min=0, alpha=1.0, background_id=10):\n",
    "        self.neg_pos_ratio = neg_pos_ratio\n",
    "        self.n_neg_min = 0\n",
    "        self.alpha = alpha\n",
    "        self.background_id = background_id\n",
    "        \n",
    "    def smoothL1Loss(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        y_true: ground truth localization tensor, shape: (batch_size, num_boxes, 4)\n",
    "        y_pred: predicted localization tensor, shape: (batch_size, num_boxes, 4)\n",
    "        \"\"\"\n",
    "        diff = tf.abs(y_pred - y_true)\n",
    "        l1_loss = tf.where(tf.less(diff, 1), 0.5 * diff ** 2, diff - 0.5)\n",
    "\n",
    "        return tf.reduce_sum(l1_loss, axis=-1)\n",
    "        \n",
    "    def compute_loss(self, y_true, y_pred):    \n",
    "        \"\"\"\n",
    "        y_true: (batch_size, # boxes, n_classes + 4)\n",
    "        y_pred: (batch_size, # boxes, n_classes + 4)\n",
    "        \"\"\"\n",
    "        #Get the size of tensor\n",
    "        batch_size = tf.shape(y_true)[0]\n",
    "        n_boxes = tf.shape(y_pred)[1]\n",
    "                \n",
    "        #classification loss\n",
    "        class_pred = y_pred[:,:,:n_classes]\n",
    "        class_true = tf.maximum(y_true[:,:,:n_classes], 1e-15)\n",
    "\n",
    "        class_loss = -tf.reduce_sum(class_true * tf.math.log(class_pred), axis = -1)\n",
    "        class_loss = tf.cast(class_loss, dtype=tf.float32) # (batch_size, n_boxes)\n",
    "\n",
    "        negatives = y_true[:,:,self.background_id] # Class is background, (batch_size, n_boxes)\n",
    "        positives = tf.cast(tf.reduce_max(y_true[:,:,:n_classes-1], axis=-1), dtype=tf.float32) # Class is NOT background, (batch_size, n_boxes)       \n",
    "\n",
    "        n_positives = tf.cast(tf.reduce_sum(positives), dtype=tf.float32) # number of positive boxes, single number\n",
    "        \n",
    "        # Loss for positive boxes\n",
    "        pos_class_loss = tf.reduce_sum(class_loss * positives, axis=-1) # (batch_size)  \n",
    "        print('pos_class_loss: ', pos_class_loss)\n",
    "        \n",
    "        #localization loss\n",
    "        loc_pred = y_pred[:,:,n_classes:]\n",
    "        loc_true = y_true[:,:,n_classes:]\n",
    "        loc_loss = tf.cast(self.smoothL1Loss(y_true, y_pred), dtype=tf.float32) # (batch_size, n_boxes)        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Include only positive boxes in calculating localization loss\n",
    "        loc_loss = tf.reduce_sum(positives * loc_loss, axis=-1) #(batch_size)        \n",
    "        print('loc loss: ', loc_loss)\n",
    "        return loc_loss\n",
    "        \n",
    "        # Loss for negative boxes\n",
    "        neg_class_loss_all = class_loss * negatives #(batch_size, n_boxes)\n",
    "        n_neg_losses = tf.math.count_nonzero(neg_class_loss_all, dtype=tf.int32) # The number of nonzero entries in neg_class_loss_all\n",
    "        \n",
    "        # Keep the number of negative boxes between n_neg_min and neg_pos_ratio * positive_boxes        \n",
    "        n_negative_keep = tf.minimum(tf.maximum(self.neg_pos_ratio * tf.cast(n_positives, dtype=tf.int32), self.n_neg_min), n_neg_losses)\n",
    "        \n",
    "        def f1():\n",
    "            return tf.zeros([batch_size])\n",
    "        \n",
    "        def f2():\n",
    "            #Resahpe neg_class_loss_all to 1d array\n",
    "            neg_class_loss_all_1D = tf.reshape(neg_class_loss_all, [-1])\n",
    "\n",
    "            # Find top 'n_negative_keep' boxes from neg_class_loss_all_1D\n",
    "            values, indices = tf.nn.top_k(neg_class_loss_all_1D, k=n_negative_keep, sorted=False)\n",
    "\n",
    "            #Then create a mask for negative boxes: For selected box above, set them as 0\n",
    "            negatives_keep = tf.scatter_nd(indices=tf.expand_dims(indices, axis=1),\n",
    "                                           updates=tf.ones_like(indices, dtype=tf.int32),\n",
    "                                           shape=tf.shape(neg_class_loss_all_1D))\n",
    "            negatives_keep = tf.cast(tf.reshape(negatives_keep, [batch_size, n_boxes]), dtype=tf.float32)            \n",
    "\n",
    "            #Finally compute negative loss\n",
    "            neg_class_loss = tf.reduce_sum(class_loss * negatives_keep, axis=-1) #(batch_size)\n",
    "            \n",
    "            return neg_class_loss\n",
    "        \n",
    "        neg_class_loss = tf.cond(tf.equal(n_neg_losses, tf.constant(0)), f1, f2)   \n",
    "        \n",
    "        \n",
    "        class_loss = pos_class_loss  + neg_class_loss\n",
    "        \n",
    "        #Combine localization and classification loss, divide by matched default box(n_positives)\n",
    "        total_loss = (class_loss + loc_loss * self.alpha) / tf.maximum(1.0, n_positives)\n",
    "        \n",
    "        # We divided by n_positives - # of all matched default boxes of \"a batch\"\n",
    "        # Since keras divides by the size of batch, it is double division\n",
    "        # To adjust this, we multiply by batch_size\n",
    "        total_loss = total_loss * tf.cast(batch_size, dtype=tf.float32)\n",
    "        print(\"total loss:\", total_loss)\n",
    "        \n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vitxnz5w9K_d"
   },
   "source": [
    "CallBack 함수를 지정하면 필요한 대로 트레이닝 옵션들을 추가할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 446,
     "status": "ok",
     "timestamp": 1613128712680,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "Ol3p__269K_d"
   },
   "outputs": [],
   "source": [
    "#decay could be applied using Learning rate scheduler\n",
    "def decay(epoch):\n",
    "    return 0.045 * (0.98 **(epoch-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 465,
     "status": "ok",
     "timestamp": 1613128713355,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "Uiy0mP-a9K_e"
   },
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "\"\"\"\n",
    "#TensorBoard로 훈련 성과를 보고 싶은 경우\n",
    "callbacks.append(TensorBoard(log_dir=log_dir, histogram_freq=1))\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "#Checkpoint설정\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "model_cp_path = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "callbacks.append(ModelCheckpoint(model_cp_path, monitor='val_loss', save_best_only=True))\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "#Learning rate 스케쥴 설정\n",
    "callbacks.append(LearningRateScheduler(decay))\n",
    "\"\"\"\n",
    "#General logs on csv\n",
    "callbacks.append(CSVLogger(model_csv_path)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxQ9ZlDY9K_e"
   },
   "source": [
    "모델을 컴파일 하고 트레이닝을 시작하자.<br>\n",
    "* Optimizer: RMSprop을 사용하고 최초 Learning rate=0.045, 매 Epoch마다 0.98씩 decay 되도록 설정해주자.\n",
    "* Loss: Categorical cross entropy를 사용하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 495,
     "status": "ok",
     "timestamp": 1613128714914,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "SubXyZLl9K_e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1, background_id=10)\n",
    "model.compile(loss=ssd_loss.compute_loss,     \n",
    "              optimizer=tf.keras.optimizers.SGD(lr=0.001, momentum=0.9, decay=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "executionInfo": {
     "elapsed": 334587,
     "status": "error",
     "timestamp": 1613129050032,
     "user": {
      "displayName": "­박건도 / 학생 / 데이터사이언스학과",
      "photoUrl": "",
      "userId": "12188535571487389353"
     },
     "user_tz": -540
    },
    "id": "7lCV7zxS9K_e",
    "outputId": "fdba39cd-8163-49b0-af90-d07bae7b92b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "pos_class_loss:  Tensor(\"compute_loss/Sum_2:0\", shape=(None,), dtype=float32)\n",
      "loc loss:  Tensor(\"compute_loss/Sum_4:0\", shape=(None,), dtype=float32)\n",
      "pos_class_loss:  Tensor(\"compute_loss/Sum_2:0\", shape=(None,), dtype=float32)\n",
      "loc loss:  Tensor(\"compute_loss/Sum_4:0\", shape=(None,), dtype=float32)\n",
      "   2/1563 [..............................] - ETA: 47:31:36 - loss: 0.6040"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-ffb200b480e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0;31m#steps_per_epoch=math.ceil(len(train_images) / batch_size),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m               verbose=1)\n\u001b[0m\u001b[1;32m      6\u001b[0m               \u001b[0;31m#callbacks=callbacks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m               \u001b[0;31m#validation_data=(val_images, val_labels))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(ds_train_encoded,\n",
    "              #datagen.flow(train_images, train_labels, batch_size=batch_size),\n",
    "              #steps_per_epoch=math.ceil(len(train_images) / batch_size),\n",
    "              epochs=100,\n",
    "              verbose=1)\n",
    "              #callbacks=callbacks)\n",
    "              #validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_FQRIkyT9K_e",
    "outputId": "3b2293f9-43bc-4ea7-b00d-d8461cad5d46"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train_od' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-153-8641c2eac605>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(x_train_od[:32], y_train_encoded[:32,:,:-4],\n\u001b[0m\u001b[0;32m      2\u001b[0m               \u001b[1;31m#datagen.flow(train_images, train_labels, batch_size=batch_size),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m               \u001b[1;31m#steps_per_epoch=math.ceil(len(train_images) / batch_size),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m               verbose=1)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train_od' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_od[:32], y_train_encoded[:32,:,:-4],\n",
    "              #datagen.flow(train_images, train_labels, batch_size=batch_size),\n",
    "              #steps_per_epoch=math.ceil(len(train_images) / batch_size),\n",
    "              epochs=100,\n",
    "              verbose=1)\n",
    "              #callbacks=callbacks)\n",
    "              #validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPHFmo349K_f"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print('Model Name: ', model_name)\n",
    "print('Test loss     : {:.5f}'.format(test_loss))\n",
    "print('Test accuracy : {:.5f}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4nqfrt_9K_f"
   },
   "source": [
    "# 과제: MobileNet 변형해 보기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "361gisYr9K_f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fcN7Yzng9K_f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4EAA-w059K_f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LEWp_oGD9K_f"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Practice_MobileNetSSD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0859bab71eab47fbb590007039f39a3e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08c9f1d4d5b54c89ba25408245698d65": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e905de5c373451b893300c1762b57fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8773c576980a46f88c96bed1b2c3ed4c",
      "placeholder": "​",
      "style": "IPY_MODEL_31eccb666655419081e2ac8d5ebcb565",
      "value": " 1/1 [00:05&lt;00:00,  5.52s/ file]"
     }
    },
    "12412c91f4174c7f862a69d35f7c13f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6e57c0dbe654a38a3699eb60cf05fcb",
      "placeholder": "​",
      "style": "IPY_MODEL_e22ac0c707a14a759dad90dfbb129e56",
      "value": " 47611/50000 [00:04&lt;01:00, 39.37 examples/s]"
     }
    },
    "2608bdced506428096e088db539c7ad9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28b40640b9fe459fb831f226cb47db77": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29040801c9c648098c6325fd9d378335": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cc56730809984a7ba5b56d23e47f2801",
       "IPY_MODEL_12412c91f4174c7f862a69d35f7c13f0"
      ],
      "layout": "IPY_MODEL_550e1b3b7b2e4fcf86af1f85a6fbc25b"
     }
    },
    "2ab7e70e71cb43839059e0c98a5588ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Dl Completed...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55c71cce9c134fe4aef64c8fad66517f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_385dc23d1c6f4a78a8a169b47ae85802",
      "value": 1
     }
    },
    "31eccb666655419081e2ac8d5ebcb565": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32709ba74bb94ca1ad8d34054055cabe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08c9f1d4d5b54c89ba25408245698d65",
      "placeholder": "​",
      "style": "IPY_MODEL_9bb929653cc44291b30b7fe1fd434112",
      "value": " 50000/0 [00:36&lt;00:00, 1460.84 examples/s]"
     }
    },
    "32fb297f13f14d7aaf620bee707b0c93": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8dda30ea6cdd49d59e78976b9cf42009",
      "placeholder": "​",
      "style": "IPY_MODEL_3f7d53d5923749dd943f3c861ce51117",
      "value": " 1/1 [00:05&lt;00:00,  5.60s/ url]"
     }
    },
    "37b62a85ad3541f186b525270faf83e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_be9a07eb56ac4c59894ed173d57293d2",
       "IPY_MODEL_dc3679c7120b43858f4f1787cb6e28cd"
      ],
      "layout": "IPY_MODEL_b43c4bbc415e444098b947a1461abd84"
     }
    },
    "385dc23d1c6f4a78a8a169b47ae85802": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3bd6270ce53849a1895099e7f8b17ccb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f7d53d5923749dd943f3c861ce51117": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "407265d3cf8049e0991a972d0d479ece": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "419af6b5b997403c95a1e65312a3e860": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0859bab71eab47fbb590007039f39a3e",
      "placeholder": "​",
      "style": "IPY_MODEL_a77b136604ec4a2cba8fe68a0d2dbf9b",
      "value": " 162/162 [00:05&lt;00:00, 29.08 MiB/s]"
     }
    },
    "472ef399bf364248ae5ade0826aaaeac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4ff7afb64cbd4186b40f92065dfb82ac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5493d675213f4e17a683ff9d6f97fc53": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "550e1b3b7b2e4fcf86af1f85a6fbc25b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55493dd5e4fd465098bc70ff37e69db0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Dl Size...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ff7afb64cbd4186b40f92065dfb82ac",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_407265d3cf8049e0991a972d0d479ece",
      "value": 1
     }
    },
    "55c71cce9c134fe4aef64c8fad66517f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "571c240f947a4d15ae78455c4a72f9b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Extraction completed...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f639f557bd10413984105589e2f4b591",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_76bae7cb1859498f8409bcd9e30a9c34",
      "value": 1
     }
    },
    "64591e2e98f04e08968607743f928be5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "76bae7cb1859498f8409bcd9e30a9c34": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7f8e45ed7b0e44d9b8a00649f8adac3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ddb41ebea79c4253b360d4daf7589ff7",
       "IPY_MODEL_aa059c294a97454e82a88da4ed3e5bdc"
      ],
      "layout": "IPY_MODEL_5493d675213f4e17a683ff9d6f97fc53"
     }
    },
    "80e50241164841aeba862927d2feee97": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_889032f1a36745f68ec2bdb4a02e027e",
       "IPY_MODEL_32709ba74bb94ca1ad8d34054055cabe"
      ],
      "layout": "IPY_MODEL_28b40640b9fe459fb831f226cb47db77"
     }
    },
    "8773c576980a46f88c96bed1b2c3ed4c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "889032f1a36745f68ec2bdb4a02e027e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd6b681892134c84b5ff7af3e7bfcf8e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_97dd481a5a4c4cc39e0938425f6a1fb3",
      "value": 1
     }
    },
    "89085c51c0654b5d8c39dba0e68bd8cb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8dda30ea6cdd49d59e78976b9cf42009": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97dd481a5a4c4cc39e0938425f6a1fb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9bb929653cc44291b30b7fe1fd434112": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a2ff4fc99413416e90a395e2d97a99e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_55493dd5e4fd465098bc70ff37e69db0",
       "IPY_MODEL_419af6b5b997403c95a1e65312a3e860"
      ],
      "layout": "IPY_MODEL_2608bdced506428096e088db539c7ad9"
     }
    },
    "a77b136604ec4a2cba8fe68a0d2dbf9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aa059c294a97454e82a88da4ed3e5bdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bd6270ce53849a1895099e7f8b17ccb",
      "placeholder": "​",
      "style": "IPY_MODEL_cb1ab90424ee4bbf980e16539a3b4415",
      "value": " 10000/0 [00:07&lt;00:00, 1368.89 examples/s]"
     }
    },
    "b431f65b3b254cc6a3e5c8b52b8cd94b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2ab7e70e71cb43839059e0c98a5588ce",
       "IPY_MODEL_32fb297f13f14d7aaf620bee707b0c93"
      ],
      "layout": "IPY_MODEL_f0f704e333824d88a1e500181657c811"
     }
    },
    "b43c4bbc415e444098b947a1461abd84": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7b66bc0f6e84e07a6f96c976625b7fe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8e2b8e04343446ab154218db45511b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_571c240f947a4d15ae78455c4a72f9b4",
       "IPY_MODEL_0e905de5c373451b893300c1762b57fd"
      ],
      "layout": "IPY_MODEL_fb775dedd2ed4a788147186b938a1cb6"
     }
    },
    "be9a07eb56ac4c59894ed173d57293d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": " 56%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbfee4abb7cd42a9b10f15891edc0d4c",
      "max": 10000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eb48fcf80e8749b38168a99e1ed35747",
      "value": 5580
     }
    },
    "bf435f29ce0d4453b06d1d47a26efcdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cb1ab90424ee4bbf980e16539a3b4415": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cbd353891b784c9385e538ba6393b264": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbfee4abb7cd42a9b10f15891edc0d4c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc56730809984a7ba5b56d23e47f2801": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": " 95%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbd353891b784c9385e538ba6393b264",
      "max": 50000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bf435f29ce0d4453b06d1d47a26efcdc",
      "value": 47611
     }
    },
    "d6e57c0dbe654a38a3699eb60cf05fcb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc3679c7120b43858f4f1787cb6e28cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7b66bc0f6e84e07a6f96c976625b7fe",
      "placeholder": "​",
      "style": "IPY_MODEL_64591e2e98f04e08968607743f928be5",
      "value": " 5580/10000 [00:20&lt;00:00, 55798.86 examples/s]"
     }
    },
    "dd6b681892134c84b5ff7af3e7bfcf8e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddb41ebea79c4253b360d4daf7589ff7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89085c51c0654b5d8c39dba0e68bd8cb",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_472ef399bf364248ae5ade0826aaaeac",
      "value": 1
     }
    },
    "e22ac0c707a14a759dad90dfbb129e56": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eb48fcf80e8749b38168a99e1ed35747": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f0f704e333824d88a1e500181657c811": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f639f557bd10413984105589e2f4b591": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb775dedd2ed4a788147186b938a1cb6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
